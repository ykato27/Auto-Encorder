{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_NumPyro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykato27/AutoEncorder/blob/main/VAE_NumPyro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXDRxifjo9Y8"
      },
      "source": [
        "!pip install numpyro==0.8.0 >> /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6MUOZNsikub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1534f13d-e11a-44fd-ddf6-c21b438c845c"
      },
      "source": [
        "import inspect\n",
        "import os\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from jax import jit, lax, random\n",
        "from jax.experimental import stax\n",
        "import jax.numpy as jnp\n",
        "from jax.random import PRNGKey\n",
        "\n",
        "import numpyro\n",
        "from numpyro import optim\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.examples.datasets import MNIST, load_dataset\n",
        "from numpyro.infer import SVI, Trace_ELBO"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/experimental/stax.py:30: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/jax/experimental/optimizers.py:30: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead\n",
            "  FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr1AgIJbAuT5"
      },
      "source": [
        "from numpyro.util import set_platform\n",
        "set_platform(\"gpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYtpjxzKiqfN"
      },
      "source": [
        "RESULTS_DIR = os.path.abspath(os.path.join(os.path.dirname(inspect.getfile(lambda: None)),\n",
        "                              '.results'))\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BSYjejNisdN"
      },
      "source": [
        "def encoder(hidden_dim, z_dim):\n",
        "    return stax.serial(\n",
        "        stax.Dense(hidden_dim, W_init=stax.randn()), stax.Softplus,\n",
        "        stax.FanOut(2),\n",
        "        stax.parallel(stax.Dense(z_dim, W_init=stax.randn()),\n",
        "                      stax.serial(stax.Dense(z_dim, W_init=stax.randn()), stax.Exp)),\n",
        "    )\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INdM_w5liu_R"
      },
      "source": [
        "def decoder(hidden_dim, out_dim):\n",
        "    return stax.serial(\n",
        "        stax.Dense(hidden_dim, W_init=stax.randn()), stax.Softplus,\n",
        "        stax.Dense(out_dim, W_init=stax.randn()), stax.Sigmoid,\n",
        "    )\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7SXnrkQixAY"
      },
      "source": [
        "def model(batch, hidden_dim=400, z_dim=100):\n",
        "    batch = jnp.reshape(batch, (batch.shape[0], -1))\n",
        "    batch_dim, out_dim = jnp.shape(batch)\n",
        "    decode = numpyro.module('decoder', decoder(hidden_dim, out_dim), (batch_dim, z_dim))\n",
        "    z = numpyro.sample('z', dist.Normal(jnp.zeros((z_dim,)), jnp.ones((z_dim,))))\n",
        "    img_loc = decode(z)\n",
        "    return numpyro.sample('obs', dist.Bernoulli(img_loc), obs=batch)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s_ZNrpoizkB"
      },
      "source": [
        "def guide(batch, hidden_dim=400, z_dim=100):\n",
        "    batch = jnp.reshape(batch, (batch.shape[0], -1))\n",
        "    batch_dim, out_dim = jnp.shape(batch)\n",
        "    encode = numpyro.module('encoder', encoder(hidden_dim, z_dim), (batch_dim, out_dim))\n",
        "    z_loc, z_std = encode(batch)\n",
        "    z = numpyro.sample('z', dist.Normal(z_loc, z_std))\n",
        "    return z\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A0G_4Avi1cV"
      },
      "source": [
        "@jit\n",
        "def binarize(rng_key, batch):\n",
        "    return random.bernoulli(rng_key, batch).astype(batch.dtype)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9RYrODii35S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "869d0863-ee1e-4988-bf8f-c0be4a3367e2"
      },
      "source": [
        "hidden_dim = 400\n",
        "z_dim = 50\n",
        "learning_rate = 1.0e-3\n",
        "batch_size = 256\n",
        "num_epochs = 100\n",
        "\n",
        "\n",
        "encoder_nn = encoder(hidden_dim, z_dim)\n",
        "decoder_nn = decoder(hidden_dim, 28 * 28)\n",
        "adam = optim.Adam(learning_rate)\n",
        "svi = SVI(model, guide, adam, Trace_ELBO(), hidden_dim=hidden_dim, z_dim=z_dim)\n",
        "rng_key = PRNGKey(0)\n",
        "train_init, train_fetch = load_dataset(MNIST, batch_size=batch_size, split='train')\n",
        "test_init, test_fetch = load_dataset(MNIST, batch_size=batch_size, split='test')\n",
        "num_train, train_idx = train_init()\n",
        "rng_key, rng_key_binarize, rng_key_init = random.split(rng_key, 3)\n",
        "sample_batch = binarize(rng_key_binarize, train_fetch(0, train_idx)[0])\n",
        "svi_state = svi.init(rng_key_init, sample_batch)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading - https://d2hg8soec8ck9v.cloudfront.net/datasets/mnist/train-images-idx3-ubyte.gz.\n",
            "Download complete.\n",
            "Downloading - https://d2hg8soec8ck9v.cloudfront.net/datasets/mnist/train-labels-idx1-ubyte.gz.\n",
            "Download complete.\n",
            "Downloading - https://d2hg8soec8ck9v.cloudfront.net/datasets/mnist/t10k-images-idx3-ubyte.gz.\n",
            "Download complete.\n",
            "Downloading - https://d2hg8soec8ck9v.cloudfront.net/datasets/mnist/t10k-labels-idx1-ubyte.gz.\n",
            "Download complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoG5Cs7MldrJ"
      },
      "source": [
        "@jit\n",
        "def epoch_train(svi_state, rng_key):\n",
        "    def body_fn(i, val):\n",
        "        loss_sum, svi_state = val\n",
        "        rng_key_binarize = random.fold_in(rng_key, i)\n",
        "        batch = binarize(rng_key_binarize, train_fetch(i, train_idx)[0])\n",
        "        svi_state, loss = svi.update(svi_state, batch)\n",
        "        loss_sum += loss\n",
        "        return loss_sum, svi_state\n",
        "\n",
        "    return lax.fori_loop(0, num_train, body_fn, (0., svi_state))\n",
        "\n",
        "@jit\n",
        "def eval_test(svi_state, rng_key):\n",
        "    def body_fun(i, loss_sum):\n",
        "        rng_key_binarize = random.fold_in(rng_key, i)\n",
        "        batch = binarize(rng_key_binarize, test_fetch(i, test_idx)[0])\n",
        "        # FIXME: does this lead to a requirement for an rng_key arg in svi_eval?\n",
        "        loss = svi.evaluate(svi_state, batch) / len(batch)\n",
        "        loss_sum += loss\n",
        "        return loss_sum\n",
        "\n",
        "    loss = lax.fori_loop(0, num_test, body_fun, 0.)\n",
        "    loss = loss / num_test\n",
        "    return loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFkmEgRMloxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6fb8728-8eab-421e-9a8f-fe543479cb74"
      },
      "source": [
        "%%time\n",
        "def reconstruct_img(epoch, rng_key):\n",
        "    img = test_fetch(0, test_idx)[0][0]\n",
        "    plt.imsave(os.path.join(RESULTS_DIR, 'original_epoch={}.png'.format(epoch)), img, cmap='gray')\n",
        "    rng_key_binarize, rng_key_sample = random.split(rng_key)\n",
        "    test_sample = binarize(rng_key_binarize, img)\n",
        "    params = svi.get_params(svi_state)\n",
        "    z_mean, z_var = encoder_nn[1](params['encoder$params'], test_sample.reshape([1, -1]))\n",
        "    z = dist.Normal(z_mean, z_var).sample(rng_key_sample)\n",
        "    img_loc = decoder_nn[1](params['decoder$params'], z).reshape([28, 28])\n",
        "    plt.imsave(os.path.join(RESULTS_DIR, 'recons_epoch={}.png'.format(epoch)), img_loc, cmap='gray')\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    rng_key, rng_key_train, rng_key_test, rng_key_reconstruct = random.split(rng_key, 4)\n",
        "    t_start = time.time()\n",
        "    num_train, train_idx = train_init()\n",
        "    _, svi_state = epoch_train(svi_state, rng_key_train)\n",
        "    rng_key, rng_key_test, rng_key_reconstruct = random.split(rng_key, 3)\n",
        "    num_test, test_idx = test_init()\n",
        "    test_loss = eval_test(svi_state, rng_key_test)\n",
        "    reconstruct_img(i, rng_key_reconstruct)\n",
        "    print(\"Epoch {}: loss = {} ({:.2f} s.)\".format(i, test_loss, time.time() - t_start))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss = 192.58180236816406 (7.52 s.)\n",
            "Epoch 1: loss = 177.60427856445312 (0.64 s.)\n",
            "Epoch 2: loss = 151.1453399658203 (0.51 s.)\n",
            "Epoch 3: loss = 134.12527465820312 (0.50 s.)\n",
            "Epoch 4: loss = 124.96324157714844 (0.50 s.)\n",
            "Epoch 5: loss = 118.43643951416016 (0.50 s.)\n",
            "Epoch 6: loss = 114.15824127197266 (0.50 s.)\n",
            "Epoch 7: loss = 111.36780548095703 (0.50 s.)\n",
            "Epoch 8: loss = 109.39195251464844 (0.50 s.)\n",
            "Epoch 9: loss = 108.26847076416016 (0.50 s.)\n",
            "Epoch 10: loss = 106.76620483398438 (0.50 s.)\n",
            "Epoch 11: loss = 105.9121322631836 (0.50 s.)\n",
            "Epoch 12: loss = 104.70977783203125 (0.50 s.)\n",
            "Epoch 13: loss = 104.19607543945312 (0.50 s.)\n",
            "Epoch 14: loss = 103.17749786376953 (0.50 s.)\n",
            "Epoch 15: loss = 102.8322525024414 (0.50 s.)\n",
            "Epoch 16: loss = 102.24053955078125 (0.50 s.)\n",
            "Epoch 17: loss = 101.92752838134766 (0.50 s.)\n",
            "Epoch 18: loss = 101.69229888916016 (0.51 s.)\n",
            "Epoch 19: loss = 101.38291931152344 (0.50 s.)\n",
            "Epoch 20: loss = 101.18970489501953 (0.50 s.)\n",
            "Epoch 21: loss = 101.13899993896484 (0.50 s.)\n",
            "Epoch 22: loss = 100.6649169921875 (0.50 s.)\n",
            "Epoch 23: loss = 100.44129180908203 (0.50 s.)\n",
            "Epoch 24: loss = 100.27626037597656 (0.50 s.)\n",
            "Epoch 25: loss = 100.07988739013672 (0.50 s.)\n",
            "Epoch 26: loss = 99.99388885498047 (0.50 s.)\n",
            "Epoch 27: loss = 100.0731430053711 (0.50 s.)\n",
            "Epoch 28: loss = 99.7826156616211 (0.50 s.)\n",
            "Epoch 29: loss = 99.52302551269531 (0.50 s.)\n",
            "Epoch 30: loss = 99.42181396484375 (0.51 s.)\n",
            "Epoch 31: loss = 99.60889434814453 (0.50 s.)\n",
            "Epoch 32: loss = 99.37564086914062 (0.50 s.)\n",
            "Epoch 33: loss = 99.06048583984375 (0.50 s.)\n",
            "Epoch 34: loss = 98.93492889404297 (0.50 s.)\n",
            "Epoch 35: loss = 98.97306823730469 (0.51 s.)\n",
            "Epoch 36: loss = 98.80062866210938 (0.50 s.)\n",
            "Epoch 37: loss = 98.79369354248047 (0.50 s.)\n",
            "Epoch 38: loss = 98.83787536621094 (0.50 s.)\n",
            "Epoch 39: loss = 98.93151092529297 (0.50 s.)\n",
            "Epoch 40: loss = 98.51615905761719 (0.50 s.)\n",
            "Epoch 41: loss = 98.53667449951172 (0.50 s.)\n",
            "Epoch 42: loss = 98.62715911865234 (0.50 s.)\n",
            "Epoch 43: loss = 98.45467376708984 (0.50 s.)\n",
            "Epoch 44: loss = 98.60004425048828 (0.50 s.)\n",
            "Epoch 45: loss = 98.49046325683594 (0.51 s.)\n",
            "Epoch 46: loss = 98.49092102050781 (0.51 s.)\n",
            "Epoch 47: loss = 98.328369140625 (0.50 s.)\n",
            "Epoch 48: loss = 98.11170196533203 (0.51 s.)\n",
            "Epoch 49: loss = 98.37362670898438 (0.50 s.)\n",
            "Epoch 50: loss = 98.13050842285156 (0.50 s.)\n",
            "Epoch 51: loss = 98.21747589111328 (0.50 s.)\n",
            "Epoch 52: loss = 98.28831481933594 (0.50 s.)\n",
            "Epoch 53: loss = 98.08204650878906 (0.50 s.)\n",
            "Epoch 54: loss = 98.00354766845703 (0.51 s.)\n",
            "Epoch 55: loss = 97.94358825683594 (0.51 s.)\n",
            "Epoch 56: loss = 97.79997253417969 (0.51 s.)\n",
            "Epoch 57: loss = 97.82656860351562 (0.50 s.)\n",
            "Epoch 58: loss = 97.77762603759766 (0.50 s.)\n",
            "Epoch 59: loss = 97.61843872070312 (0.50 s.)\n",
            "Epoch 60: loss = 97.95207977294922 (0.51 s.)\n",
            "Epoch 61: loss = 97.5679931640625 (0.50 s.)\n",
            "Epoch 62: loss = 97.69247436523438 (0.50 s.)\n",
            "Epoch 63: loss = 97.928466796875 (0.50 s.)\n",
            "Epoch 64: loss = 97.6143569946289 (0.50 s.)\n",
            "Epoch 65: loss = 97.6479721069336 (0.50 s.)\n",
            "Epoch 66: loss = 97.48694610595703 (0.50 s.)\n",
            "Epoch 67: loss = 97.36280822753906 (0.50 s.)\n",
            "Epoch 68: loss = 97.30608367919922 (0.50 s.)\n",
            "Epoch 69: loss = 97.37190246582031 (0.50 s.)\n",
            "Epoch 70: loss = 97.23868560791016 (0.50 s.)\n",
            "Epoch 71: loss = 97.38346862792969 (0.50 s.)\n",
            "Epoch 72: loss = 97.16708374023438 (0.50 s.)\n",
            "Epoch 73: loss = 97.2563705444336 (0.50 s.)\n",
            "Epoch 74: loss = 97.17537689208984 (0.50 s.)\n",
            "Epoch 75: loss = 97.20865631103516 (0.50 s.)\n",
            "Epoch 76: loss = 97.03341674804688 (0.50 s.)\n",
            "Epoch 77: loss = 97.18490600585938 (0.51 s.)\n",
            "Epoch 78: loss = 97.08997344970703 (0.50 s.)\n",
            "Epoch 79: loss = 97.08222961425781 (0.50 s.)\n",
            "Epoch 80: loss = 96.89884185791016 (0.50 s.)\n",
            "Epoch 81: loss = 96.93042755126953 (0.51 s.)\n",
            "Epoch 82: loss = 96.91751861572266 (0.50 s.)\n",
            "Epoch 83: loss = 97.01605987548828 (0.50 s.)\n",
            "Epoch 84: loss = 96.7600326538086 (0.50 s.)\n",
            "Epoch 85: loss = 97.16521453857422 (0.50 s.)\n",
            "Epoch 86: loss = 97.12293243408203 (0.50 s.)\n",
            "Epoch 87: loss = 96.86363983154297 (0.50 s.)\n",
            "Epoch 88: loss = 96.9122314453125 (0.50 s.)\n",
            "Epoch 89: loss = 96.80945587158203 (0.50 s.)\n",
            "Epoch 90: loss = 96.6229019165039 (0.50 s.)\n",
            "Epoch 91: loss = 96.8940658569336 (0.50 s.)\n",
            "Epoch 92: loss = 96.87035369873047 (0.50 s.)\n",
            "Epoch 93: loss = 96.74888610839844 (0.50 s.)\n",
            "Epoch 94: loss = 96.75533294677734 (0.50 s.)\n",
            "Epoch 95: loss = 96.56502532958984 (0.50 s.)\n",
            "Epoch 96: loss = 96.6482162475586 (0.50 s.)\n",
            "Epoch 97: loss = 96.7944564819336 (0.50 s.)\n",
            "Epoch 98: loss = 96.40617370605469 (0.50 s.)\n",
            "Epoch 99: loss = 96.45668029785156 (0.50 s.)\n",
            "CPU times: user 38.2 s, sys: 19.4 s, total: 57.5 s\n",
            "Wall time: 57.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7mZIaHYghIt8"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}