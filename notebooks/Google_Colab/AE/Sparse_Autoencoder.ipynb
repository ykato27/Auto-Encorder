{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "colab": {
   "name": "Sparse_Autoencoder.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ykato27/Auto-Encorder/blob/main/Sparse_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQLB7tmKMBz8"
   },
   "source": [
    "## Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6xQJnH3MQG6",
    "outputId": "11f085e3-a73b-4513-b40f-af5a351a9e49"
   },
   "source": [
    "!pip install pycodestyle flake8 pycodestyle_magic"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
      "Requirement already satisfied: flake8 in /usr/local/lib/python3.7/dist-packages (3.9.2)\n",
      "Requirement already satisfied: pycodestyle_magic in /usr/local/lib/python3.7/dist-packages (0.5)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from flake8) (0.6.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from flake8) (4.6.1)\n",
      "Requirement already satisfied: pyflakes<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from flake8) (2.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->flake8) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->flake8) (3.7.4.3)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XJ4mjEkPMSpW"
   },
   "source": [
    "%load_ext pycodestyle_magic"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O4BYI1G1L_Vl"
   },
   "source": [
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bhgTzmLeL_Vm"
   },
   "source": [
    "encoding_dim = 32\n",
    "l1 = 1e-6\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# activity regularizerを加える\n",
    "encoded = Dense(\n",
    "    encoding_dim, activation=\"relu\", activity_regularizer=regularizers.l1(l1)\n",
    ")(input_img)\n",
    "decoded = Dense(784, activation=\"sigmoid\")(encoded)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "l1 = 10e-7  # L1正則化のパラメータ\n",
    "enc_dim = 512  # 隠れ層のユニット数\n",
    "\n",
    "autoencoder.compile(optimizer=\"adadelta\", loss=\"binary_crossentropy\")"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0ILf0h-L_Vn",
    "outputId": "e8fd6918-9b39-4448-d608-9be026bd715e"
   },
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000, 784)\n",
      "(10000, 784)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kSmmIwzL_Vo",
    "outputId": "30179d23-820b-4827-a981-2497ac408408"
   },
   "source": [
    "autoencoder.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=500,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test),\n",
    ")"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "235/235 [==============================] - 17s 11ms/step - loss: 0.6946 - val_loss: 0.6946\n",
      "Epoch 2/500\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.6945 - val_loss: 0.6944\n",
      "Epoch 3/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6944 - val_loss: 0.6943\n",
      "Epoch 4/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6942 - val_loss: 0.6942\n",
      "Epoch 5/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6941 - val_loss: 0.6940\n",
      "Epoch 6/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6940 - val_loss: 0.6939\n",
      "Epoch 7/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6939 - val_loss: 0.6938\n",
      "Epoch 8/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6938 - val_loss: 0.6937\n",
      "Epoch 9/500\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.6936 - val_loss: 0.6935\n",
      "Epoch 10/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6935 - val_loss: 0.6934\n",
      "Epoch 11/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6934 - val_loss: 0.6933\n",
      "Epoch 12/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6933 - val_loss: 0.6932\n",
      "Epoch 13/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 14/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6930 - val_loss: 0.6930\n",
      "Epoch 15/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6929 - val_loss: 0.6928\n",
      "Epoch 16/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6928 - val_loss: 0.6927\n",
      "Epoch 17/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6927 - val_loss: 0.6926\n",
      "Epoch 18/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6926 - val_loss: 0.6925\n",
      "Epoch 19/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6925 - val_loss: 0.6924\n",
      "Epoch 20/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6924 - val_loss: 0.6923\n",
      "Epoch 21/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6922 - val_loss: 0.6922\n",
      "Epoch 22/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6921 - val_loss: 0.6920\n",
      "Epoch 23/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6920 - val_loss: 0.6919\n",
      "Epoch 24/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6919 - val_loss: 0.6918\n",
      "Epoch 25/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6918 - val_loss: 0.6917\n",
      "Epoch 26/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6917 - val_loss: 0.6916\n",
      "Epoch 27/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6916 - val_loss: 0.6915\n",
      "Epoch 28/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6915 - val_loss: 0.6914\n",
      "Epoch 29/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6913 - val_loss: 0.6912\n",
      "Epoch 30/500\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.6912 - val_loss: 0.6911\n",
      "Epoch 31/500\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.6911 - val_loss: 0.6910\n",
      "Epoch 32/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6910 - val_loss: 0.6909\n",
      "Epoch 33/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6909 - val_loss: 0.6908\n",
      "Epoch 34/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6908 - val_loss: 0.6907\n",
      "Epoch 35/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6906 - val_loss: 0.6905\n",
      "Epoch 36/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6905 - val_loss: 0.6904\n",
      "Epoch 37/500\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.6904 - val_loss: 0.6903\n",
      "Epoch 38/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6903 - val_loss: 0.6902\n",
      "Epoch 39/500\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.6902 - val_loss: 0.6901\n",
      "Epoch 40/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6900 - val_loss: 0.6899\n",
      "Epoch 41/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6899 - val_loss: 0.6898\n",
      "Epoch 42/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6898 - val_loss: 0.6897\n",
      "Epoch 43/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6897 - val_loss: 0.6896\n",
      "Epoch 44/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6896 - val_loss: 0.6894\n",
      "Epoch 45/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6894 - val_loss: 0.6893\n",
      "Epoch 46/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6893 - val_loss: 0.6892\n",
      "Epoch 47/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6892 - val_loss: 0.6890\n",
      "Epoch 48/500\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.6890 - val_loss: 0.6889\n",
      "Epoch 49/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6889 - val_loss: 0.6888\n",
      "Epoch 50/500\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.6888 - val_loss: 0.6886\n",
      "Epoch 51/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6886 - val_loss: 0.6885\n",
      "Epoch 52/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6885 - val_loss: 0.6884\n",
      "Epoch 53/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6883 - val_loss: 0.6882\n",
      "Epoch 54/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6882 - val_loss: 0.6881\n",
      "Epoch 55/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6881 - val_loss: 0.6879\n",
      "Epoch 56/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6879 - val_loss: 0.6878\n",
      "Epoch 57/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6878 - val_loss: 0.6876\n",
      "Epoch 58/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6876 - val_loss: 0.6874\n",
      "Epoch 59/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6874 - val_loss: 0.6873\n",
      "Epoch 60/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6873 - val_loss: 0.6871\n",
      "Epoch 61/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6871 - val_loss: 0.6869\n",
      "Epoch 62/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6869 - val_loss: 0.6868\n",
      "Epoch 63/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6868 - val_loss: 0.6866\n",
      "Epoch 64/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6866 - val_loss: 0.6864\n",
      "Epoch 65/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6864 - val_loss: 0.6862\n",
      "Epoch 66/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6862 - val_loss: 0.6861\n",
      "Epoch 67/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6861 - val_loss: 0.6859\n",
      "Epoch 68/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6859 - val_loss: 0.6857\n",
      "Epoch 69/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6857 - val_loss: 0.6855\n",
      "Epoch 70/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6855 - val_loss: 0.6853\n",
      "Epoch 71/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6853 - val_loss: 0.6851\n",
      "Epoch 72/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6851 - val_loss: 0.6848\n",
      "Epoch 73/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6849 - val_loss: 0.6846\n",
      "Epoch 74/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6846 - val_loss: 0.6844\n",
      "Epoch 75/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6844 - val_loss: 0.6842\n",
      "Epoch 76/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6842 - val_loss: 0.6839\n",
      "Epoch 77/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6839 - val_loss: 0.6837\n",
      "Epoch 78/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6837 - val_loss: 0.6834\n",
      "Epoch 79/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6835 - val_loss: 0.6832\n",
      "Epoch 80/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6832 - val_loss: 0.6829\n",
      "Epoch 81/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6829 - val_loss: 0.6827\n",
      "Epoch 82/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6827 - val_loss: 0.6824\n",
      "Epoch 83/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6824 - val_loss: 0.6821\n",
      "Epoch 84/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6821 - val_loss: 0.6818\n",
      "Epoch 85/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6818 - val_loss: 0.6815\n",
      "Epoch 86/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6815 - val_loss: 0.6812\n",
      "Epoch 87/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6812 - val_loss: 0.6809\n",
      "Epoch 88/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6809 - val_loss: 0.6806\n",
      "Epoch 89/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6806 - val_loss: 0.6802\n",
      "Epoch 90/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6803 - val_loss: 0.6799\n",
      "Epoch 91/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6799 - val_loss: 0.6795\n",
      "Epoch 92/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6796 - val_loss: 0.6792\n",
      "Epoch 93/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6792 - val_loss: 0.6788\n",
      "Epoch 94/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6788 - val_loss: 0.6784\n",
      "Epoch 95/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6785 - val_loss: 0.6780\n",
      "Epoch 96/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6781 - val_loss: 0.6776\n",
      "Epoch 97/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6777 - val_loss: 0.6772\n",
      "Epoch 98/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6773 - val_loss: 0.6768\n",
      "Epoch 99/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6768 - val_loss: 0.6763\n",
      "Epoch 100/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6764 - val_loss: 0.6759\n",
      "Epoch 101/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6759 - val_loss: 0.6754\n",
      "Epoch 102/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6755 - val_loss: 0.6749\n",
      "Epoch 103/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6750 - val_loss: 0.6744\n",
      "Epoch 104/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6745 - val_loss: 0.6739\n",
      "Epoch 105/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6740 - val_loss: 0.6734\n",
      "Epoch 106/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6735 - val_loss: 0.6729\n",
      "Epoch 107/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6729 - val_loss: 0.6723\n",
      "Epoch 108/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6724 - val_loss: 0.6717\n",
      "Epoch 109/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6718 - val_loss: 0.6711\n",
      "Epoch 110/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6713 - val_loss: 0.6705\n",
      "Epoch 111/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6706 - val_loss: 0.6699\n",
      "Epoch 112/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6700 - val_loss: 0.6692\n",
      "Epoch 113/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6694 - val_loss: 0.6686\n",
      "Epoch 114/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6687 - val_loss: 0.6679\n",
      "Epoch 115/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6680 - val_loss: 0.6672\n",
      "Epoch 116/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6673 - val_loss: 0.6665\n",
      "Epoch 117/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6666 - val_loss: 0.6657\n",
      "Epoch 118/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6659 - val_loss: 0.6650\n",
      "Epoch 119/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6652 - val_loss: 0.6642\n",
      "Epoch 120/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6643 - val_loss: 0.6634\n",
      "Epoch 121/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6635 - val_loss: 0.6625\n",
      "Epoch 122/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6627 - val_loss: 0.6617\n",
      "Epoch 123/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6618 - val_loss: 0.6608\n",
      "Epoch 124/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6609 - val_loss: 0.6599\n",
      "Epoch 125/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6601 - val_loss: 0.6589\n",
      "Epoch 126/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6591 - val_loss: 0.6580\n",
      "Epoch 127/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6582 - val_loss: 0.6570\n",
      "Epoch 128/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6572 - val_loss: 0.6560\n",
      "Epoch 129/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6562 - val_loss: 0.6549\n",
      "Epoch 130/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6552 - val_loss: 0.6538\n",
      "Epoch 131/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6540 - val_loss: 0.6527\n",
      "Epoch 132/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6530 - val_loss: 0.6516\n",
      "Epoch 133/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6518 - val_loss: 0.6504\n",
      "Epoch 134/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6507 - val_loss: 0.6493\n",
      "Epoch 135/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6495 - val_loss: 0.6480\n",
      "Epoch 136/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6483 - val_loss: 0.6468\n",
      "Epoch 137/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6470 - val_loss: 0.6455\n",
      "Epoch 138/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6457 - val_loss: 0.6441\n",
      "Epoch 139/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6444 - val_loss: 0.6428\n",
      "Epoch 140/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6432 - val_loss: 0.6414\n",
      "Epoch 141/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6417 - val_loss: 0.6400\n",
      "Epoch 142/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6403 - val_loss: 0.6385\n",
      "Epoch 143/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6389 - val_loss: 0.6370\n",
      "Epoch 144/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6373 - val_loss: 0.6355\n",
      "Epoch 145/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6358 - val_loss: 0.6339\n",
      "Epoch 146/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6344 - val_loss: 0.6323\n",
      "Epoch 147/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6327 - val_loss: 0.6306\n",
      "Epoch 148/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6310 - val_loss: 0.6289\n",
      "Epoch 149/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6294 - val_loss: 0.6272\n",
      "Epoch 150/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6277 - val_loss: 0.6254\n",
      "Epoch 151/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6258 - val_loss: 0.6236\n",
      "Epoch 152/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6241 - val_loss: 0.6218\n",
      "Epoch 153/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6222 - val_loss: 0.6199\n",
      "Epoch 154/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6204 - val_loss: 0.6179\n",
      "Epoch 155/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6184 - val_loss: 0.6160\n",
      "Epoch 156/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6165 - val_loss: 0.6140\n",
      "Epoch 157/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6146 - val_loss: 0.6119\n",
      "Epoch 158/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6125 - val_loss: 0.6098\n",
      "Epoch 159/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6104 - val_loss: 0.6077\n",
      "Epoch 160/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6082 - val_loss: 0.6055\n",
      "Epoch 161/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6062 - val_loss: 0.6033\n",
      "Epoch 162/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.6040 - val_loss: 0.6010\n",
      "Epoch 163/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.6016 - val_loss: 0.5987\n",
      "Epoch 164/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5993 - val_loss: 0.5964\n",
      "Epoch 165/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5972 - val_loss: 0.5940\n",
      "Epoch 166/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5948 - val_loss: 0.5916\n",
      "Epoch 167/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5923 - val_loss: 0.5891\n",
      "Epoch 168/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5899 - val_loss: 0.5866\n",
      "Epoch 169/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5875 - val_loss: 0.5841\n",
      "Epoch 170/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5848 - val_loss: 0.5815\n",
      "Epoch 171/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5822 - val_loss: 0.5789\n",
      "Epoch 172/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5797 - val_loss: 0.5763\n",
      "Epoch 173/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5772 - val_loss: 0.5736\n",
      "Epoch 174/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5743 - val_loss: 0.5709\n",
      "Epoch 175/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5718 - val_loss: 0.5681\n",
      "Epoch 176/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5689 - val_loss: 0.5653\n",
      "Epoch 177/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5662 - val_loss: 0.5625\n",
      "Epoch 178/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5635 - val_loss: 0.5596\n",
      "Epoch 179/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.5607 - val_loss: 0.5568\n",
      "Epoch 180/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5578 - val_loss: 0.5539\n",
      "Epoch 181/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5549 - val_loss: 0.5509\n",
      "Epoch 182/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5521 - val_loss: 0.5480\n",
      "Epoch 183/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5492 - val_loss: 0.5450\n",
      "Epoch 184/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5460 - val_loss: 0.5420\n",
      "Epoch 185/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5432 - val_loss: 0.5389\n",
      "Epoch 186/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5401 - val_loss: 0.5359\n",
      "Epoch 187/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5371 - val_loss: 0.5328\n",
      "Epoch 188/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5340 - val_loss: 0.5297\n",
      "Epoch 189/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5310 - val_loss: 0.5266\n",
      "Epoch 190/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5277 - val_loss: 0.5235\n",
      "Epoch 191/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5246 - val_loss: 0.5204\n",
      "Epoch 192/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5215 - val_loss: 0.5172\n",
      "Epoch 193/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5187 - val_loss: 0.5141\n",
      "Epoch 194/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5154 - val_loss: 0.5109\n",
      "Epoch 195/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5124 - val_loss: 0.5077\n",
      "Epoch 196/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5092 - val_loss: 0.5046\n",
      "Epoch 197/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5059 - val_loss: 0.5014\n",
      "Epoch 198/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5029 - val_loss: 0.4982\n",
      "Epoch 199/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.5000 - val_loss: 0.4951\n",
      "Epoch 200/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4968 - val_loss: 0.4919\n",
      "Epoch 201/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4934 - val_loss: 0.4887\n",
      "Epoch 202/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4904 - val_loss: 0.4856\n",
      "Epoch 203/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4873 - val_loss: 0.4825\n",
      "Epoch 204/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4840 - val_loss: 0.4793\n",
      "Epoch 205/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4808 - val_loss: 0.4762\n",
      "Epoch 206/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4776 - val_loss: 0.4731\n",
      "Epoch 207/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4748 - val_loss: 0.4700\n",
      "Epoch 208/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4716 - val_loss: 0.4669\n",
      "Epoch 209/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4687 - val_loss: 0.4639\n",
      "Epoch 210/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4655 - val_loss: 0.4608\n",
      "Epoch 211/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4624 - val_loss: 0.4578\n",
      "Epoch 212/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4597 - val_loss: 0.4548\n",
      "Epoch 213/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4569 - val_loss: 0.4519\n",
      "Epoch 214/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4536 - val_loss: 0.4489\n",
      "Epoch 215/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4508 - val_loss: 0.4460\n",
      "Epoch 216/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4479 - val_loss: 0.4431\n",
      "Epoch 217/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4448 - val_loss: 0.4403\n",
      "Epoch 218/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4422 - val_loss: 0.4375\n",
      "Epoch 219/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4393 - val_loss: 0.4347\n",
      "Epoch 220/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4364 - val_loss: 0.4319\n",
      "Epoch 221/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4338 - val_loss: 0.4292\n",
      "Epoch 222/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4310 - val_loss: 0.4265\n",
      "Epoch 223/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4283 - val_loss: 0.4238\n",
      "Epoch 224/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4255 - val_loss: 0.4212\n",
      "Epoch 225/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4231 - val_loss: 0.4186\n",
      "Epoch 226/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4205 - val_loss: 0.4160\n",
      "Epoch 227/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4182 - val_loss: 0.4135\n",
      "Epoch 228/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4157 - val_loss: 0.4110\n",
      "Epoch 229/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4130 - val_loss: 0.4086\n",
      "Epoch 230/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4107 - val_loss: 0.4062\n",
      "Epoch 231/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4082 - val_loss: 0.4038\n",
      "Epoch 232/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4057 - val_loss: 0.4015\n",
      "Epoch 233/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4033 - val_loss: 0.3992\n",
      "Epoch 234/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.4012 - val_loss: 0.3969\n",
      "Epoch 235/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3989 - val_loss: 0.3947\n",
      "Epoch 236/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3968 - val_loss: 0.3925\n",
      "Epoch 237/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3946 - val_loss: 0.3904\n",
      "Epoch 238/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3926 - val_loss: 0.3883\n",
      "Epoch 239/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3903 - val_loss: 0.3862\n",
      "Epoch 240/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3884 - val_loss: 0.3842\n",
      "Epoch 241/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3866 - val_loss: 0.3822\n",
      "Epoch 242/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3841 - val_loss: 0.3803\n",
      "Epoch 243/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3825 - val_loss: 0.3783\n",
      "Epoch 244/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3806 - val_loss: 0.3765\n",
      "Epoch 245/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3788 - val_loss: 0.3746\n",
      "Epoch 246/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3769 - val_loss: 0.3728\n",
      "Epoch 247/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3752 - val_loss: 0.3710\n",
      "Epoch 248/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3731 - val_loss: 0.3693\n",
      "Epoch 249/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3714 - val_loss: 0.3676\n",
      "Epoch 250/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3700 - val_loss: 0.3659\n",
      "Epoch 251/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3681 - val_loss: 0.3643\n",
      "Epoch 252/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3663 - val_loss: 0.3627\n",
      "Epoch 253/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3645 - val_loss: 0.3611\n",
      "Epoch 254/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.3630 - val_loss: 0.3596\n",
      "Epoch 255/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3616 - val_loss: 0.3581\n",
      "Epoch 256/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3604 - val_loss: 0.3566\n",
      "Epoch 257/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3589 - val_loss: 0.3552\n",
      "Epoch 258/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3571 - val_loss: 0.3538\n",
      "Epoch 259/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3558 - val_loss: 0.3524\n",
      "Epoch 260/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3546 - val_loss: 0.3511\n",
      "Epoch 261/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3532 - val_loss: 0.3497\n",
      "Epoch 262/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3519 - val_loss: 0.3484\n",
      "Epoch 263/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3505 - val_loss: 0.3472\n",
      "Epoch 264/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3493 - val_loss: 0.3459\n",
      "Epoch 265/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3482 - val_loss: 0.3447\n",
      "Epoch 266/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3463 - val_loss: 0.3435\n",
      "Epoch 267/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3456 - val_loss: 0.3424\n",
      "Epoch 268/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3444 - val_loss: 0.3412\n",
      "Epoch 269/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3432 - val_loss: 0.3401\n",
      "Epoch 270/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3420 - val_loss: 0.3390\n",
      "Epoch 271/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3413 - val_loss: 0.3380\n",
      "Epoch 272/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3400 - val_loss: 0.3369\n",
      "Epoch 273/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3390 - val_loss: 0.3359\n",
      "Epoch 274/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3381 - val_loss: 0.3349\n",
      "Epoch 275/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3369 - val_loss: 0.3339\n",
      "Epoch 276/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3358 - val_loss: 0.3330\n",
      "Epoch 277/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3349 - val_loss: 0.3321\n",
      "Epoch 278/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3341 - val_loss: 0.3312\n",
      "Epoch 279/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.3331 - val_loss: 0.3303\n",
      "Epoch 280/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3322 - val_loss: 0.3294\n",
      "Epoch 281/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3316 - val_loss: 0.3285\n",
      "Epoch 282/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3304 - val_loss: 0.3277\n",
      "Epoch 283/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3295 - val_loss: 0.3269\n",
      "Epoch 284/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3289 - val_loss: 0.3261\n",
      "Epoch 285/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3278 - val_loss: 0.3253\n",
      "Epoch 286/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3271 - val_loss: 0.3245\n",
      "Epoch 287/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3263 - val_loss: 0.3238\n",
      "Epoch 288/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3255 - val_loss: 0.3231\n",
      "Epoch 289/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3249 - val_loss: 0.3223\n",
      "Epoch 290/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3239 - val_loss: 0.3216\n",
      "Epoch 291/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3238 - val_loss: 0.3209\n",
      "Epoch 292/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3226 - val_loss: 0.3203\n",
      "Epoch 293/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3222 - val_loss: 0.3196\n",
      "Epoch 294/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3216 - val_loss: 0.3190\n",
      "Epoch 295/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.3208 - val_loss: 0.3183\n",
      "Epoch 296/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.3204 - val_loss: 0.3177\n",
      "Epoch 297/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3193 - val_loss: 0.3171\n",
      "Epoch 298/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3191 - val_loss: 0.3165\n",
      "Epoch 299/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3179 - val_loss: 0.3159\n",
      "Epoch 300/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3176 - val_loss: 0.3154\n",
      "Epoch 301/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3172 - val_loss: 0.3148\n",
      "Epoch 302/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3167 - val_loss: 0.3143\n",
      "Epoch 303/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3161 - val_loss: 0.3137\n",
      "Epoch 304/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3155 - val_loss: 0.3132\n",
      "Epoch 305/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3144 - val_loss: 0.3127\n",
      "Epoch 306/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3145 - val_loss: 0.3122\n",
      "Epoch 307/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3139 - val_loss: 0.3117\n",
      "Epoch 308/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3134 - val_loss: 0.3112\n",
      "Epoch 309/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3130 - val_loss: 0.3107\n",
      "Epoch 310/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3124 - val_loss: 0.3103\n",
      "Epoch 311/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3119 - val_loss: 0.3098\n",
      "Epoch 312/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3117 - val_loss: 0.3094\n",
      "Epoch 313/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3108 - val_loss: 0.3089\n",
      "Epoch 314/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3105 - val_loss: 0.3085\n",
      "Epoch 315/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3101 - val_loss: 0.3081\n",
      "Epoch 316/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3097 - val_loss: 0.3077\n",
      "Epoch 317/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3093 - val_loss: 0.3073\n",
      "Epoch 318/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3092 - val_loss: 0.3069\n",
      "Epoch 319/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3088 - val_loss: 0.3065\n",
      "Epoch 320/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3086 - val_loss: 0.3061\n",
      "Epoch 321/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.3077 - val_loss: 0.3057\n",
      "Epoch 322/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3074 - val_loss: 0.3053\n",
      "Epoch 323/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3072 - val_loss: 0.3050\n",
      "Epoch 324/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3070 - val_loss: 0.3046\n",
      "Epoch 325/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3064 - val_loss: 0.3043\n",
      "Epoch 326/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3059 - val_loss: 0.3039\n",
      "Epoch 327/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3058 - val_loss: 0.3036\n",
      "Epoch 328/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3053 - val_loss: 0.3033\n",
      "Epoch 329/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3045 - val_loss: 0.3029\n",
      "Epoch 330/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3047 - val_loss: 0.3026\n",
      "Epoch 331/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3042 - val_loss: 0.3023\n",
      "Epoch 332/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3038 - val_loss: 0.3020\n",
      "Epoch 333/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3036 - val_loss: 0.3017\n",
      "Epoch 334/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3030 - val_loss: 0.3014\n",
      "Epoch 335/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3033 - val_loss: 0.3011\n",
      "Epoch 336/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3023 - val_loss: 0.3008\n",
      "Epoch 337/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3023 - val_loss: 0.3005\n",
      "Epoch 338/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3021 - val_loss: 0.3003\n",
      "Epoch 339/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3017 - val_loss: 0.3000\n",
      "Epoch 340/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3014 - val_loss: 0.2997\n",
      "Epoch 341/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.3010 - val_loss: 0.2995\n",
      "Epoch 342/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3012 - val_loss: 0.2992\n",
      "Epoch 343/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3005 - val_loss: 0.2989\n",
      "Epoch 344/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3008 - val_loss: 0.2987\n",
      "Epoch 345/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.3003 - val_loss: 0.2984\n",
      "Epoch 346/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3000 - val_loss: 0.2982\n",
      "Epoch 347/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2998 - val_loss: 0.2980\n",
      "Epoch 348/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2996 - val_loss: 0.2977\n",
      "Epoch 349/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2988 - val_loss: 0.2975\n",
      "Epoch 350/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2991 - val_loss: 0.2973\n",
      "Epoch 351/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2987 - val_loss: 0.2970\n",
      "Epoch 352/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2983 - val_loss: 0.2968\n",
      "Epoch 353/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2984 - val_loss: 0.2966\n",
      "Epoch 354/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2980 - val_loss: 0.2964\n",
      "Epoch 355/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2978 - val_loss: 0.2962\n",
      "Epoch 356/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2977 - val_loss: 0.2960\n",
      "Epoch 357/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2976 - val_loss: 0.2957\n",
      "Epoch 358/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2970 - val_loss: 0.2955\n",
      "Epoch 359/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2971 - val_loss: 0.2953\n",
      "Epoch 360/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2968 - val_loss: 0.2952\n",
      "Epoch 361/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2963 - val_loss: 0.2950\n",
      "Epoch 362/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2965 - val_loss: 0.2948\n",
      "Epoch 363/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2958 - val_loss: 0.2946\n",
      "Epoch 364/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2960 - val_loss: 0.2944\n",
      "Epoch 365/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2964 - val_loss: 0.2942\n",
      "Epoch 366/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2954 - val_loss: 0.2940\n",
      "Epoch 367/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2953 - val_loss: 0.2938\n",
      "Epoch 368/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2952 - val_loss: 0.2937\n",
      "Epoch 369/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2954 - val_loss: 0.2935\n",
      "Epoch 370/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2951 - val_loss: 0.2933\n",
      "Epoch 371/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2947 - val_loss: 0.2932\n",
      "Epoch 372/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2945 - val_loss: 0.2930\n",
      "Epoch 373/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2941 - val_loss: 0.2928\n",
      "Epoch 374/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2940 - val_loss: 0.2927\n",
      "Epoch 375/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2941 - val_loss: 0.2925\n",
      "Epoch 376/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2941 - val_loss: 0.2924\n",
      "Epoch 377/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2937 - val_loss: 0.2922\n",
      "Epoch 378/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2938 - val_loss: 0.2920\n",
      "Epoch 379/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2933 - val_loss: 0.2919\n",
      "Epoch 380/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2935 - val_loss: 0.2917\n",
      "Epoch 381/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2927 - val_loss: 0.2916\n",
      "Epoch 382/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2930 - val_loss: 0.2914\n",
      "Epoch 383/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2927 - val_loss: 0.2913\n",
      "Epoch 384/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2923 - val_loss: 0.2912\n",
      "Epoch 385/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2923 - val_loss: 0.2910\n",
      "Epoch 386/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2925 - val_loss: 0.2909\n",
      "Epoch 387/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2922 - val_loss: 0.2907\n",
      "Epoch 388/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2920 - val_loss: 0.2906\n",
      "Epoch 389/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2922 - val_loss: 0.2905\n",
      "Epoch 390/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2920 - val_loss: 0.2903\n",
      "Epoch 391/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2913 - val_loss: 0.2902\n",
      "Epoch 392/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2917 - val_loss: 0.2901\n",
      "Epoch 393/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2910 - val_loss: 0.2900\n",
      "Epoch 394/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2911 - val_loss: 0.2898\n",
      "Epoch 395/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2909 - val_loss: 0.2897\n",
      "Epoch 396/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2913 - val_loss: 0.2896\n",
      "Epoch 397/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2907 - val_loss: 0.2895\n",
      "Epoch 398/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2904 - val_loss: 0.2893\n",
      "Epoch 399/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2908 - val_loss: 0.2892\n",
      "Epoch 400/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2904 - val_loss: 0.2891\n",
      "Epoch 401/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2902 - val_loss: 0.2890\n",
      "Epoch 402/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2902 - val_loss: 0.2889\n",
      "Epoch 403/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2904 - val_loss: 0.2888\n",
      "Epoch 404/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2899 - val_loss: 0.2887\n",
      "Epoch 405/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2900 - val_loss: 0.2885\n",
      "Epoch 406/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2896 - val_loss: 0.2884\n",
      "Epoch 407/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2896 - val_loss: 0.2883\n",
      "Epoch 408/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2894 - val_loss: 0.2882\n",
      "Epoch 409/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2891 - val_loss: 0.2881\n",
      "Epoch 410/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2894 - val_loss: 0.2880\n",
      "Epoch 411/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2893 - val_loss: 0.2879\n",
      "Epoch 412/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2895 - val_loss: 0.2878\n",
      "Epoch 413/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2887 - val_loss: 0.2877\n",
      "Epoch 414/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2890 - val_loss: 0.2876\n",
      "Epoch 415/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2888 - val_loss: 0.2875\n",
      "Epoch 416/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2891 - val_loss: 0.2874\n",
      "Epoch 417/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2884 - val_loss: 0.2873\n",
      "Epoch 418/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2884 - val_loss: 0.2872\n",
      "Epoch 419/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2888 - val_loss: 0.2871\n",
      "Epoch 420/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2886 - val_loss: 0.2870\n",
      "Epoch 421/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2883 - val_loss: 0.2869\n",
      "Epoch 422/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2881 - val_loss: 0.2868\n",
      "Epoch 423/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2877 - val_loss: 0.2867\n",
      "Epoch 424/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2875 - val_loss: 0.2867\n",
      "Epoch 425/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2881 - val_loss: 0.2866\n",
      "Epoch 426/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2879 - val_loss: 0.2865\n",
      "Epoch 427/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2876 - val_loss: 0.2864\n",
      "Epoch 428/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2876 - val_loss: 0.2863\n",
      "Epoch 429/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2874 - val_loss: 0.2862\n",
      "Epoch 430/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2872 - val_loss: 0.2861\n",
      "Epoch 431/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2869 - val_loss: 0.2860\n",
      "Epoch 432/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2870 - val_loss: 0.2860\n",
      "Epoch 433/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2872 - val_loss: 0.2859\n",
      "Epoch 434/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2868 - val_loss: 0.2858\n",
      "Epoch 435/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2871 - val_loss: 0.2857\n",
      "Epoch 436/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2870 - val_loss: 0.2856\n",
      "Epoch 437/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2870 - val_loss: 0.2855\n",
      "Epoch 438/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2867 - val_loss: 0.2855\n",
      "Epoch 439/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2865 - val_loss: 0.2854\n",
      "Epoch 440/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2864 - val_loss: 0.2853\n",
      "Epoch 441/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2860 - val_loss: 0.2852\n",
      "Epoch 442/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2867 - val_loss: 0.2852\n",
      "Epoch 443/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2862 - val_loss: 0.2851\n",
      "Epoch 444/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2863 - val_loss: 0.2850\n",
      "Epoch 445/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2864 - val_loss: 0.2849\n",
      "Epoch 446/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2861 - val_loss: 0.2849\n",
      "Epoch 447/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2867 - val_loss: 0.2848\n",
      "Epoch 448/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2862 - val_loss: 0.2847\n",
      "Epoch 449/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2862 - val_loss: 0.2846\n",
      "Epoch 450/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2859 - val_loss: 0.2846\n",
      "Epoch 451/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2856 - val_loss: 0.2845\n",
      "Epoch 452/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2858 - val_loss: 0.2844\n",
      "Epoch 453/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2855 - val_loss: 0.2844\n",
      "Epoch 454/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2856 - val_loss: 0.2843\n",
      "Epoch 455/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2854 - val_loss: 0.2842\n",
      "Epoch 456/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2856 - val_loss: 0.2842\n",
      "Epoch 457/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2854 - val_loss: 0.2841\n",
      "Epoch 458/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2850 - val_loss: 0.2840\n",
      "Epoch 459/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2853 - val_loss: 0.2840\n",
      "Epoch 460/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2852 - val_loss: 0.2839\n",
      "Epoch 461/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2848 - val_loss: 0.2838\n",
      "Epoch 462/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2849 - val_loss: 0.2838\n",
      "Epoch 463/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2849 - val_loss: 0.2837\n",
      "Epoch 464/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2849 - val_loss: 0.2836\n",
      "Epoch 465/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2846 - val_loss: 0.2836\n",
      "Epoch 466/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2846 - val_loss: 0.2835\n",
      "Epoch 467/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2845 - val_loss: 0.2835\n",
      "Epoch 468/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2844 - val_loss: 0.2834\n",
      "Epoch 469/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2847 - val_loss: 0.2833\n",
      "Epoch 470/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2845 - val_loss: 0.2833\n",
      "Epoch 471/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2844 - val_loss: 0.2832\n",
      "Epoch 472/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2845 - val_loss: 0.2832\n",
      "Epoch 473/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2842 - val_loss: 0.2831\n",
      "Epoch 474/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2844 - val_loss: 0.2830\n",
      "Epoch 475/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2843 - val_loss: 0.2830\n",
      "Epoch 476/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2839 - val_loss: 0.2829\n",
      "Epoch 477/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2840 - val_loss: 0.2829\n",
      "Epoch 478/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2840 - val_loss: 0.2828\n",
      "Epoch 479/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2838 - val_loss: 0.2828\n",
      "Epoch 480/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2838 - val_loss: 0.2827\n",
      "Epoch 481/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2836 - val_loss: 0.2826\n",
      "Epoch 482/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2842 - val_loss: 0.2826\n",
      "Epoch 483/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2838 - val_loss: 0.2825\n",
      "Epoch 484/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2840 - val_loss: 0.2825\n",
      "Epoch 485/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2837 - val_loss: 0.2824\n",
      "Epoch 486/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2835 - val_loss: 0.2824\n",
      "Epoch 487/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2839 - val_loss: 0.2823\n",
      "Epoch 488/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2834 - val_loss: 0.2823\n",
      "Epoch 489/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2836 - val_loss: 0.2822\n",
      "Epoch 490/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2831 - val_loss: 0.2822\n",
      "Epoch 491/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2835 - val_loss: 0.2821\n",
      "Epoch 492/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2830 - val_loss: 0.2821\n",
      "Epoch 493/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2834 - val_loss: 0.2820\n",
      "Epoch 494/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.2832 - val_loss: 0.2820\n",
      "Epoch 495/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2831 - val_loss: 0.2819\n",
      "Epoch 496/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2833 - val_loss: 0.2819\n",
      "Epoch 497/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2830 - val_loss: 0.2818\n",
      "Epoch 498/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2828 - val_loss: 0.2818\n",
      "Epoch 499/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.2825 - val_loss: 0.2817\n",
      "Epoch 500/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2829 - val_loss: 0.2817\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1331554910>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DOOPWos5L_Vp"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# テスト画像を変換\n",
    "decoded_imgs = autoencoder.predict(x_test)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Do8FRYztL_Vp",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "outputId": "f86b4757-27e0-4968-9f0b-9db1c5fbbe72"
   },
   "source": [
    "# 何個表示するか\n",
    "# plt.subplot(行数, 列数, 何番目のプロットか)\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # オリジナルのテスト画像を表示\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # 変換された画像を表示\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)  # 軸の値の表示を無効化\n",
    "    ax.get_yaxis().set_visible(False)  # 軸の値の表示を無効化\n",
    "plt.show()"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABG0AAADnCAYAAACkCqtqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29ebgdVZX+v08iKggiBMIgkEBCGAUEBLXFFuVxQHEEpaVt29kW2xm11a/i/DygOAvSTzvhhAPOSDu0EyrtA0JoZgmQEOYARgMkDDm/P/ydzbvf3L1S56TOvZWbz+evXam6Vbv22tOprHetXr/fTwAAAAAAAAAA0C1mTHUFAAAAAAAAAABgTfhoAwAAAAAAAADQQfhoAwAAAAAAAADQQfhoAwAAAAAAAADQQfhoAwAAAAAAAADQQfhoAwAAAAAAAADQQR4wzMW9Xo/84FNEv9/vtXEfbDilLOv3+1u3cSPsOHUwFqcFjMVpAGNxWsBYnAYwFqcFjMVpAGNxWjDhWMTTBmDyWDzVFQCAlBJjEaArMBYBugFjEaAbTDgW+WgDAAAAAAAAANBB+GgDAAAAAAAAANBB+GgDAAAAAAAAANBB+GgDAAAAAAAAANBB+GgDAAAAAAAAANBB+GgDAAAAAAAAANBB+GgDAAAAAAAAANBB+GgDAAAAAAAAANBBHjDVFYANk7e85S25vPHGGxfn9tlnn1w+8sgjq/c4+eSTc/kPf/hDce60005b1yoCAAAAAAAATCl42gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBBi2sCkcfrpp+dyFKtGWb16dfXcq171qlw+7LDDinO//vWvc3nJkiVNqwhTzIIFC4rjyy67LJdf//rX5/KnPvWpSavThsxDHvKQXD7xxBNzWcdeSimdd955uXzUUUcV5xYvXjym2gEAAABMDVtssUUu77TTTo3+xvdEb3zjG3P5oosuyuUrrriiuG7hwoWjVBGmEXjaAAAAAAAAAAB0ED7aAAAAAAAAAAB0EORRMDZUDpVSc0mUSmL++7//O5d32WWX4rojjjgil+fNm1ecO+aYY3L5wx/+cKPnwtTzyEc+sjhWedzSpUsnuzobPNttt10uv+IVr8hlly0ecMABufyMZzyjOPeZz3xmTLUDZf/998/lM844ozg3d+7csT33yU9+cnF86aWX5vK11147tufC2tE1MqWUfvCDH+Tya1/72lw+5ZRTiuvuu+++8VZsGjJ79uxc/uY3v5nLv//974vrTj311Fy+5pprxl6vAZtvvnlx/PjHPz6XzzrrrFy+5557Jq1OAOsDT3/603P5mc98ZnHuCU94Qi7Pnz+/0f1c9jRnzpxcftCDHlT9u5kzZza6P0xf8LQBAAAAAAAAAOggfLQBAAAAAAAAAOggyKOgVQ488MBcfs5znlO97uKLL85ldzdctmxZLq9YsSKXH/jABxbXnXPOObm87777FudmzZrVsMbQJfbbb7/i+I477sjl7373u5NdnQ2Orbfeujj+0pe+NEU1gWF5ylOeksuRi3XbuATnpS99aS4fffTRk1YP+Du69n32s5+tXvfpT386lz//+c8X5+666672KzbN0KwxKZV7GpUi3XTTTcV1UyWJ0gx/KZVzvcpbr7zyyvFXbD3joQ99aHGskvu99947lz2LKVKzbqNhFY499thcVil4SiltvPHGudzr9db5uZ4lFaApeNoAAAAAAAAAAHQQPtoAAAAAAAAAAHQQPtoAAAAAAAAAAHSQKY1p4ymgVUd4/fXXF+dWrlyZy1/96ldz+cYbbyyuQ487tWiKYNd+quZb4y/ccMMNje795je/uTjec889q9f++Mc/bnRPmHpUE65paFNK6bTTTpvs6mxwvO51r8vlZz/72cW5gw46aOj7aSrZlFKaMeP+/xtYuHBhLv/mN78Z+t5Q8oAH3L+EH3744VNSB4+V8aY3vSmXH/KQhxTnNEYVjAcdfzvssEP1uq9//eu5rPsrqLPVVlvl8umnn16c23LLLXNZYwn9+7//+/grVuFd73pXLu+8887FuVe96lW5zL55TY455phc/uAHP1ic23HHHSf8G499c+utt7ZfMWgNnR9f//rXj/VZl112WS7rbyFoD025rnN1SmWMVU3TnlJKq1evzuVTTjkll3/3u98V13VhnsTTBgAAAAAAAACgg/DRBgAAAAAAAACgg0ypPOqEE04ojufOndvo79St829/+1txbjLdzpYuXZrL/i7nnnvupNWjS/zwhz/MZXVVS6m01W233Tb0vT197EYbbTT0PaB77L777rnscgp3QYf2+djHPpbL6iY6Ks997nOrx4sXL87lF7zgBcV1LrOBtXPooYfm8mMe85hc9vVonHjqY5WtbrLJJsU55FHt4+nd3/nOdzb6O5We9vv9Vus0Xdl///1z2V3slfe9732TUJs12WuvvYpjlZR/97vfLc6xtq6JymU+/vGP5/KsWbOK62rj5VOf+lRxrHLvUfa80AyXwqjUSSUuZ511VnHdqlWrcnn58uW57OuU7kt/+tOfFucuuuiiXP7f//3fXD7//POL6+66667q/aE5Gk4hpXKM6V7T+0RTDj744Fy+9957i3OXX355Lp999tnFOe1zd99990jPbgKeNgAAAAAAAAAAHYSPNgAAAAAAAAAAHYSPNgAAAAAAAAAAHWRKY9poiu+UUtpnn31y+dJLLy3O7bHHHrkc6Yof/ehH5/K1116by7UUfROhOrZbbrkllzWdtbNkyZLieEONaaNo/IpROe6443J5wYIF1etUSzrRMXSXt771rbnsfYZxNB7OPPPMXNaU3KOiqU1XrFhRnJszZ04ua9rZP/7xj8V1M2fOXOd6THdcz61pmxctWpTLH/rQhyatTs961rMm7VmwJo94xCOK4wMOOKB6re5tfvKTn4ytTtOF2bNnF8fPe97zqte+7GUvy2XdN44bjWPz85//vHqdx7TxeJCQ0lve8pZc1hTuTfE4bU996lNz2dOGa/ybccbAmK5EcWb23XffXNZUz84555yTy/q78pprrimu22mnnXJZY5mm1E4cQFgT/R5w7LHH5rKPsYc+9KET/v11111XHP/2t7/N5auvvro4p79BNLbiQQcdVFync8Lhhx9enFu4cGEua9rwtsHTBgAAAAAAAACgg/DRBgAAAAAAAACgg0ypPOoXv/hFeKx4qrYBnm50v/32y2V1c3rUox7VuF4rV67M5SuuuCKXXbKlrlLqmg7rxjOe8Yxc1tSZD3zgA4vrbr755lz+j//4j+LcnXfeOabawboyd+7c4vjAAw/MZR1vKZEasS3+8R//sTjebbfdclnde5u6+rr7p7ona+rMlFJ64hOfmMtROuJ/+7d/y+WTTz65UT02NN71rncVx+oirq74LlFrG137vG/hLj65RJIdx2UEEPPRj360OP7nf/7nXNb9ZUopfetb35qUOjmHHHJILm+zzTbFuS9+8Yu5/JWvfGWyqrTeoNLdlFJ6yUteMuF1F154YXF800035fJhhx1Wvf/mm2+eyyq9Simlr371q7l84403rr2yGzi+///a176WyyqHSqmUB0eSQcUlUYqHv4D2+dznPlccq6wtSt+t3w3+7//+L5ff8Y53FNfp73rnsY99bC7rPvTzn/98cZ1+X9A5IKWUPvOZz+Tyd77znVxuWyqLpw0AAAAAAAAAQAfhow0AAAAAAAAAQAeZUnlUG9x+++3F8S9/+csJr4ukVxHqeuxSLHXFOv3000e6P6yJymXcJVLRNv/1r3891jpBe7icQpnMrBvTHZWhfeMb3yjORe6mimbzUpfP9773vcV1kRxR7/HKV74yl7feeuviuhNOOCGXH/zgBxfnPv3pT+fyPffcs7ZqTyuOPPLIXPaMBVdeeWUuT2amNZW5uRzqV7/6VS7/5S9/mawqbbA8/vGPr57zrDSRPBHWpN/vF8fa16+//vri3DgzAG288cbFsbr+v+Y1r8llr+9LX/rSsdVpOqByh5RS2myzzXJZs834nkXXp3/6p3/KZZdkzJs3L5e33Xbb4tz3v//9XH7a056Wy7fddlujum8IbLrpprnsIRA0jMKyZcuKcx/5yEdymVAJ3cH3dZq16eUvf3lxrtfr5bL+LnDp/IknnpjLo4ZTmDVrVi5rFtPjjz++uE7DtLi0crLA0wYAAAAAAAAAoIPw0QYAAAAAAAAAoIPw0QYAAAAAAAAAoIOs9zFtxsHs2bNz+bOf/Wwuz5hRfuPSdNToUEfne9/7XnH85Cc/ecLrvvzlLxfHnv4W1g8e8YhHVM9pXBNYNx7wgPun96YxbDw21NFHH53Lrhtvisa0+fCHP5zLJ510UnHdJptsksveD37wgx/k8qJFi0aqx/rKUUcdlcvaRimV69O40RhJxxxzTC7fd999xXUf+MAHcnlDiz80WWiKUi07rvG/4IILxlanDY2nP/3pxbGmU9dYTh6DoSkaR+UJT3hCce7Rj370hH/z7W9/e6Rnbag86EEPKo41JtDHPvax6t9p+uAvfOELuaxzdUop7bLLLtV7aKyVccZDWp959rOfnctvf/vbi3OahlvT3qeU0vLly8dbMRgJn8eOO+64XNYYNimldN111+Wyxpb94x//ONKzNVbNjjvuWJzT35ZnnnlmLnscW8Xre9ppp+XyOGP54WkDAAAAAAAAANBB+GgDAAAAAAAAANBBkEdNwLHHHpvLmpbW04tffvnlk1an6cZ2222Xy+7erS6rKslQt/uUUlqxYsWYagdto+7cL3nJS4pz559/fi7/7Gc/m7Q6wd/RVNGeInZUSVQNlTmpxCallB71qEe1+qz1lc0337w4rkkhUhpdejEKmq5d5XaXXnppcd0vf/nLSavThkrTsTKZ/WM68olPfKI4PvTQQ3N5++23L85p6nV1nX/mM5850rP1Hp7KW7nqqqty2VNOQ4ym63ZU/uYS/hoHHnhg42efc845ucxedmIi6afuG5cuXToZ1YF1RCVKKa0prVbuvffeXD744INz+cgjjyyu23333Sf8+7vuuqs43mOPPSYsp1Tuc7fZZptqnZSbbrqpOJ4sWTieNgAAAAAAAAAAHYSPNgAAAAAAAAAAHQR5VErpH/7hH4pjj1I+QCOZp5TSRRddNLY6TXe+853v5PKsWbOq133lK1/J5Q0ta8x04rDDDsvlLbfcsjh31lln5bJmZYD28Mx3irqejht1+fc6RXU8/vjjc/lFL3pR6/XqEp7R5OEPf3guf/3rX5/s6mTmzZs34b+zDk4+kQyjjcxF8HfOO++84nifffbJ5f32268499SnPjWXNSvKLbfcUlz3pS99qdGzNRvJwoULq9f9/ve/z2X2SMPh86lK2VSC6BIMzYD5nOc8J5c924yORT/3ile8IpfV1pdcckmjum8IuBRG0fH2nve8pzj3/e9/P5fJmNcd/ud//qc4Vim1/kZIKaWddtoplz/5yU/mciQVVbmVS7EiapKo1atXF8ff/e53c/l1r3tdce6GG25o/Lx1AU8bAAAAAAAAAIAOwkcbAAAAAAAAAIAOwkcbAAAAAAAAAIAOQkyblNLhhx9eHG+00Ua5/Itf/CKX//CHP0xanaYjqhfef//9q9f96le/ymXXqsL6yb777pvLrkn99re/PdnV2SB49atfncuuzZ0qjjjiiFx+5CMfWZzTOnp9NabNdOdvf/tbcayafI2pkVIZH+q2225rtR6zZ88ujmvxBc4+++xWnwsT87jHPS6XX/jCF1avW758eS6TCrddbr/99lz21PZ6/La3vW2dn7XLLrvkssYCS6mcE97ylres87M2VH7+858Xxzp2NG6Nx5mpxdXw+x177LG5/KMf/ag4t+uuu+ayxsfQdXtDZ+utt85l3xNo7Ld3v/vdxbl3vetduXzKKafksqZZT6mMm3LllVfm8sUXX1yt01577VUc6+9C5tsYT8Ot8aAe9rCHFec0tqzGnb311luL65YsWZLL2if0N0dKKR100EFD1/fUU08tjt/xjnfkssarmkzwtAEAAAAAAAAA6CB8tAEAAAAAAAAA6CAbrDxq4403zmVNHZdSSnfffXcuqzznnnvuGX/FphGeyltdy1SC5qjr74oVK9qvGEwK2267bS4fcsghuXz55ZcX12kaPWgPlSJNJurSnFJKe+65Zy7rHBDhaXI3pLnXXYg1je/znve84tyPf/zjXD7ppJOGftbee+9dHKskY+7cucW5miSgK9K76Y6upzNm1P+/7Wc/+9lkVAfGjEo+fOyp/MrnSmiOS0qf//zn57LKtjfffPPqPT71qU/lssviVq5cmctnnHFGcU7lH095ylNyed68ecV1G3Ia94985CO5/KY3vanx3+n8+JrXvGbCclvo+NPQDkcffXTrz5rOuNxIx8cofPnLXy6OI3mUStK1n33xi18srtOU4lMFnjYAAAAAAAAAAB2EjzYAAAAAAAAAAB2EjzYAAAAAAAAAAB1kg41pc9xxx+Wyp54966yzcvn3v//9pNVpuvHmN7+5OH7Uox414XXf+973imPSfE8P/vVf/zWXNX3wT37ykymoDUwW73znO4tjTXsacc011+Tyi1/84uKcpnXc0ND50FP/Pv3pT8/lr3/960Pfe9myZcWxxs7YaqutGt3Ddd8wHmop1z0WwOc+97nJqA60zFFHHVUc/8u//Esua8yFlNZMewvtoCm7dby98IUvLK7TMaexhzSGjfP+97+/ON5jjz1y+ZnPfOaE90tpzbVwQ0Ljmpx++unFua997Wu5/IAHlD9ld9xxx1yO4n+1gcbw0z6jacdTSukDH/jAWOsBKb31rW/N5WFiCr361a/O5VH2UZMJnjYAAAAAAAAAAB2EjzYAAAAAAAAAAB1kg5FHqRt5Sin9v//3/3L5r3/9a3Hufe9736TUabrTNEXfa1/72uKYNN/Tgzlz5kz477fffvsk1wTGzZlnnpnLu+2220j3uOSSS3L57LPPXuc6TRcuu+yyXNaUtCmltN9+++Xy/Pnzh763prV1vvSlLxXHxxxzzITXeYpyaIcddtihOHaJxoClS5cWx+eee+7Y6gTj42lPe1r13I9+9KPi+E9/+tO4q7PBo1IpLY+Kz5Mq91F51KGHHlpct+WWW+aypyif7miKZZ/XFixYUP27Jz3pSbm80UYb5fLxxx9fXFcL2TAqKl8+4IADWr03TMzLX/7yXFZJmkvmlIsvvrg4PuOMM9qv2JjA0wYAAAAAAAAAoIPw0QYAAAAAAAAAoINMa3nUrFmzcvmTn/xkcW7mzJm5rK79KaV0zjnnjLdiUKDunymldM899wx9j+XLl1fvoe6Rm2++efUeD3vYw4rjpvIudeF829veVpy78847G91jOvKMZzxjwn//4Q9/OMk12TBRV90og0Lkln/qqafm8vbbb1+9Tu+/evXqplUsOOKII0b6uw2ZCy64YMJyG1x11VWNrtt7772L44suuqjVemyoPPaxjy2Oa2PYsy/C+onPw3fccUcuf/SjH53s6sCY+eY3v5nLKo96wQteUFyn4QMI3dCMX/ziFxP+u8qJUyrlUffee28uf+ELXyiu+8///M9cfsMb3lCcq8lWYTwcdNBBxbHOjZtuumn17zTshmaLSimlVatWtVS78YOnDQAAAAAAAABAB+GjDQAAAAAAAABAB+GjDQAAAAAAAABAB5l2MW00Vs1ZZ52VyzvvvHNx3aJFi3JZ03/D5HPhhReu8z2+9a1vFcc33HBDLm+zzTa57HrhtrnxxhuL4w9+8INjfV6XeNzjHlccb7vttlNUE0gppZNPPjmXTzjhhOp1mk42ikfTNFZN0+tOOeWURtfB1KAxkSY6HkAMm/GgMfmcZcuW5fInPvGJyagOjAGNraD7lJRSuvnmm3OZFN/TD10ndX1+1rOeVVz3nve8J5e/8Y1vFOeuuOKKMdVuevLTn/60ONb9uaaIfsUrXlFcN3/+/Fx+whOe0OhZS5cuHaGGsDY89uFmm2024XUaEyylMm7U7373u/YrNkngaQMAAAAAAAAA0EH4aAMAAAAAAAAA0EGmnTxq3rx5uXzAAQdUr9N0ziqVgvbwVOru9tkmRx111Eh/p2n+IlnHD37wg1w+99xzq9f99re/Hake04HnPOc5xbFKFc8///xc/s1vfjNpddqQOeOMM3L5uOOOK85tvfXWY3vuLbfcUhxfeumlufzKV74yl1XCCN2j3++HxzBenvKUp1TPLVmyJJeXL18+GdWBMaDyKB9fP/7xj6t/p5KALbbYIpe1X8D6wwUXXJDL7373u4tzJ554Yi5/6EMfKs696EUvyuW77rprTLWbPuheJKUy7frzn//86t8deuih1XP33XdfLuuYffvb3z5KFWECdL5761vf2uhvvvrVrxbHv/rVr9qs0pSBpw0AAAAAAAAAQAfhow0AAAAAAAAAQAfhow0AAAAAAAAAQAdZ72PazJkzpzj2lG4DPKaDprmF8fDc5z63OFYt4kYbbdToHnvttVcuD5Ou+/Of/3wuX3PNNdXrvvOd7+TyZZdd1vj+8Hc22WSTXD788MOr133729/OZdUAw/hYvHhxLh999NHFuWc/+9m5/PrXv77V53qa+8985jOt3h8mhwc/+MHVc8RPGA+6Lmp8PmflypW5fM8994y1TjA16Dp5zDHHFOfe+MY35vLFF1+cyy9+8YvHXzEYK1/+8peL41e96lW57Hvq973vfbl84YUXjrdi0wBft97whjfk8qabbprLBx54YHHd7Nmzc9l/T5x22mm5fPzxx7dQS0iptMcll1ySy9FvRx0DatvpBJ42AAAAAAAAAAAdhI82AAAAAAAAAAAdZL2XR2kK2ZRS2mmnnSa87te//nVxTPrSyeeEE05Yp79/4Qtf2FJNoC3UNf/2228vzmma9E984hOTVidYE0+zrscqKfX59Igjjshlteepp55aXNfr9XJZXVlh/eUlL3lJcfyXv/wll9///vdPdnU2CFavXp3L5557bnFu7733zuUrr7xy0uoEU8PLX/7yXH7Zy15WnPuv//qvXGYsTi9uueWW4viwww7LZZfmvO1tb8tll9DB2rnppptyWfc6mko9pZQe/ehH5/J73/ve4tzNN988ptpt2DzxiU/M5R122CGXo9/uKhtVCfF0Ak8bAAAAAAAAAIAOwkcbAAAAAAAAAIAO0htGJtTr9TqhKXrc4x6Xy2eeeWZxTiNOKwcddFBx7K7HXaff7/fWftXa6YoNN1DO6/f7B679srWDHacOxuK0gLG4Fn74wx8WxyeddFIu//KXv5zs6kzIdB6L22+/fXH8gQ98IJfPO++8XJ4G2dk22LGoe1nNBJRSKWE9+eSTi3MqRb777rvHVLvhmM5jsSt4dtzHPOYxuXzwwQfn8jpIlDfYsTidmA5jceHChbn8iEc8onrdiSeemMsqF5wGTDgW8bQBAAAAAAAAAOggfLQBAAAAAAAAAOggfLQBAAAAAAAAAOgg62XK70MOOSSXazFsUkpp0aJFubxixYqx1gkAAGC6oClQYfK5/vrri+OXvvSlU1QTGBdnn312LmuKW4CJOPLII4tjjfsxf/78XF6HmDYAnWDLLbfM5V7v/hA9nmL94x//+KTVqQvgaQMAAAAAAAAA0EH4aAMAAAAAAAAA0EHWS3lUhLoLPulJT8rl2267bSqqAwAAAAAAMDJ//etfi+Odd955imoCMF5OOumkCcvvf//7i+tuuOGGSatTF8DTBgAAAAAAAACgg/DRBgAAAAAAAACgg/DRBgAAAAAAAACgg/T6/X7zi3u95hdDq/T7/d7ar1o72HBKOa/f7x/Yxo2w49TBWJwWMBanAYzFaQFjcRrAWJwWMBanAYzFacGEYxFPGwAAAAAAAACADsJHGwAAAAAAAACADjJsyu9lKaXF46gIhMxp8V7YcOrAjus/2HB6gB3Xf7Dh9AA7rv9gw+kBdlz/wYbTgwntOFRMGwAAAAAAAAAAmByQRwEAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdBA+2gAAAAAAAAAAdJAHDHNxr9frz5jx9+88/X4/um6kykT31HN6/1Gfpfg99Fm15/q5CL1u0H4DVq9eXT2n1/T7/XV/0fR3G9baLHrXpjRtkzbs1jZed61j034QvVe/31/W7/e3Xtd6ppTSjBkz+jNnzlzj+RM8szhuYvu1ndPjQR3WRtM28nM6PpRoHHl99dpovN1333257O81uGfbY7GN+8BItDoWm6yL0ViszTVru0dtXHnfrt0zqlN0j1HWPr9/tC5OxVhsYsMJ/m7Cfx/Ghk3uNypN9yyTvbexvtTaWBzVjm3Qxv6pxqj2GeVvomfV7Njv98eyR226f2mLpuOj6d+3Ud9RbN2FPSr7m6mDPeq0YMKxONRHmxkzZqSHPOQhKaWU7r777uJctNlTdAOmG7OUyonFf6zptRtttNGEz52ovrX7aT28vvfcc8+Ef+ebRz3n76LX6v0e9KAHFdfddddduTxo2wGD9rjzzjtTW/R6vfTgBz84pbRmnfXY26TpD4zaj2y//wMeUO96UR9RtI5NP7w50XV6z6gfqH0HbTvg3nvv1esWVysyJDNnzkxbbLHFGs9PqWwXP/fABz5wwvutXLmy+iy/h9pk0003Des40T28b+mx94tVq1ZN+NxNNtmkuO6OO+7IZbejjjl9T7/H8uXLc/mhD31ocW5Q/zbHYkr397FRf2CsZQM20j2b3H/UzWnbP6SG2Zzas1sbizNmzMjjIFrT/JyORe33PhZ1fOh8ktZ/j5gAACAASURBVFI5rvR+vs7439XqpGN24403Ls7pmq/3iz64+HpQm5t8HtGxuNlmmxXnBs9ucyzOmDEjv6+3ifYjP1dbx2rtPdE9tI3Uht5/a+uRo20crVXaN/09fM6v3V/fxdcW3dv4uqh/t2rVqlbH4sCOboPIjtpOUTtH+4Xah0a3QVM76nV+j1r/ij6cRXuppn3B7Tj4u2j/MCy9Xi/PX/6e+n7RWhL9Bmm6R9V7RHsWxetb61dejzb2qJENde72tUFZuXJla2Mxpfvff9T/zIh+w0X3GOU/M5r+x8mo/5nR9GN9G/+Z0Sbr+hG8abs6o3wEj57V9l65jf/kX0tfmnAsDvXRpt/v50nJK6Kdyc/VFvloc+ToDyxdIPQDTkplh402Htrh/QOU3lM3ht7AOkFHm7naD+WUys2qT/iDerT9vwuDukYTQkT0cS363zVt11E+hkVeHd522v5q36i/+LvUflRFP76ij4NRfxyFQb/w+mif9Y8PWr9oU6hjzM/pjyj9qOIbhdo93Fb6sVLvl1K5SfzLX/5SvYf2Nd9A6o9PfZbXd9asWbnsthqM0zY3p8ow/5M66iLY5B5tLGxNF8tR33mUZ/m5cf0vvM952p99s1z7z4Gob/v76fqhP5KjjyVap2hO9Y8ieq0+yz+46Hzk40jHs45Ln8M233zzXPZ3GdxjXGPR+4auH7UfrSnFfS/aH+neRp/l81Ntffb66t9F66La0J+ldXQbqt2i//zSudbrrmPB5/x1QfeokR19T1abD6I9qv+N9g19p+hDSvTvkR213Zvuh/0eWl+9zu+h9ajtb9reow6e4/fVd/B61n48D/NjX++pz4o+uET/2Rn9oK/Z0OcY7Uv+LjqOomfpHBOtL5NF0x+uTT9sOdq2TT9iNP2A6tc1/c/dph/fIntEY3Hwd21/tGnipTvqvrHpx7GmXpu13zdre1bNhqN6ODZ1Jmn64af4+0Y1AAAAAAAAAACASYWPNgAAAAAAAAAAHYSPNgAAAAAAAAAAHWTY7FFZj9U0O8Xg7yYiim3hqG60psVNqdSkRrrJKA5JLeBpVF/X19f0ft4WkZ57UK+2NYo1RokHEenpI2rxbVKqB2+LNMFRsD/V/TbtL35t1L+1v0xWtoN+v5/7jvdttUFT7azGN0ipjCnhsTi0r2t8g7UEuJvwuSmVNvD+o9dutdVW1fp67B5F2yCK4aHBT10vP4jrMFljsSltBF4bJchbdG7UPh+9S9P5dLIzxjjR86O4FE3XqijApK6LkZ7eYyYoei4KCq5j8W9/+1v1HlEA2igwfRRLbvB3bY7Ffr+f7xvFWHNq8Qc8Foq2QxQbT+fQaJ6M4s/pdT6PKVGAa61HFL8wWu+jOb9p/LxRGPT1qG5RooUoHoqud35O2zCKY1h7rrdzLV6JP0vrFMUwcqI5R4ni89TiB60rTWwY7RuVKJZPFBQ8av9a2/l12g+i9Tnao+o9PL5ULYaKP6vJ74xxMmqikIgo1lstBkoU3L1pfJWmyQ+iuHJN47xEc68zbjsOs6+rXRu1idN0fmq692xa/8hOTW04jhg/uQ5rvQIAAAAAAAAAACYdPtoAAAAAAAAAAHSQoeRRKd3v9hNJVTyFthKl7IvSO+s5dQeN3Mc0NbE/S90FXZal0gt1R3TXND1u6qoZueXWrm1bYjOwXeRqF7nyR+nXIvmJtmUkiVHUNdTvrffztLPaB6OUiXocpZCNXE+nKmVizYVY6+fSBR072s9VBrg2tG233nrrXI7c/h/2sIflsttqxYoVubzDDjsU5zTNt17ncijtC/7Oek77UyR3rLnRjivN8DC07Yre1KU06uc6jqL+GEkO23CZjhhXyu9+v1+Vskapk7UvRqmeI7mjPk/7r6932td1rNdkgBPVoyZ/9Ou0Tn/961+Lc9oe+ndRfWvpqMcpPZ3oeSmtKTPQetfWNydy5VfbRJIilXi4XbSOOj+nVNoj2qfpsyJpRTSmtA0iW0X1GIVBu/n+Ruvnz9T1PZJ/Rf2yljbbr9N+orbzdVElgr4+69pdSz/t+LpY28f5PaL5Z/B3vpauK4NnRjaM3jVKw930nPbZpvL7aGzr3iulclzpWhD9zvA1pLa2+ns1lZe0TZN1dpS0x8PcU/tv9K5q46hfuPRR+77awPcCWqdovERynzZk6MNS+82vjCr3GrYOa7tHLbSG18Pn5Npv+WiPGs0/bbxzDTxtAAAAAAAAAAA6CB9tAAAAAAAAAAA6CB9tAAAAAAAAAAA6yNAxbQa4nks1gFE8Gj3n2kDVa7r+UzW9qt13HfD222+fy6r73mabbYrr9O/uuOOO4pzqnW+88cZcVo1xSindcMMNuey6co2/EcUY0dgcNb18pCkfhYGtovgLUZwZPee2rqUvTam0d6Tl3nLLLXNZNfl+P207t4222e23357L3v633XZbLqvN/B7aVm4P7WdRLKA2mTFjRm7PyI5RbAWN+eQaXo3doul9U0pp1qxZuazj0ses/p2OS00nnlLZn3wsqk1qNk2pTNft/eSmm27KZR3bGi8npXKO8Pt7ndumDV33MOkO1d5a9nFfm2t97lZbqy1SKud1janh40jHsI+jWjrLcejhh6XX6+Vx3jStt1+r7e7jSPusx7bQMaw28TGr1+2yyy5F3RWdy/yc1uP666/PZZ97ly1blss+r+j41ra59dZbi+u0/h4Xx9unDdSGo6YljeKvadv5eqfrmLa/21rnXS1rvDB/tvdHXf80LorPdzo3+hqi9tC9nd4vpbLPeSywaF0aF01jz+lY9L/RucztU9uj+nXat/W6nXbaqbhObaB7opTKMadjUfczKZXjysez26v279pffc4e9LVxxV10ovm0FtMlikvk65jaQ8eillMqbajzkc+7es77kq6T2ub6myOl0qY+bvTvtD18vGk9/LfbOGOj1OKhNF2no5h6tXTnKZXtpGW3t869OsaidTb6raFj1q/TedP3ubUYN/7v2pej3+Bt0mQf1TQNenRdFDcqin+ne3Pd+3vcS7Wh10PtFtlQf4+4bWo2HCb1e5NxgacNAAAAAAAAAEAH4aMNAAAAAAAAAEAHGVoeVXPBUrfRyM0pcsWbPXt2LkfSmvnz5+fy3Llzi+vUbVjPubxBXYpV5uQsWbIkl9319M9//vOE1/k9o5SWkevZoE3bdvOv2bAmQXDUhv436krrbmzqrqZymYc//OHFddoP5s2bV72ullI6pdJW1157bS6rzVJK6eqrr87lpUuXFufUtVhdIKPU1n5uXBKNXq9XdTFXt1sfi1WXO6v3nDlzctnHoo6x7bbbLpd9LNbkUWrflEpXUU9pqdx88825rC7hKZUSqCglu7oNRy767h47rrE4oKl76drOKZFkVd1Ndey4bdS+mo591113La5T93GfE9TddPHixbl86aWXFtfpnOlzbc0NvOmcNU405Xck+XU3fbVJJKNU+0TSGp0f3T66/qkMw2XDkcu5rnH77LNPLuscmlI5x7pc4LLLLsvlyI66ZtYkKm2PxZrUQ+f+YSSIiraDSy3UhjrefL3bcccdc1ltqPNxSuV65C70Ov/peLvuuuuK69TW3g/UHto2kaS66Tq0rkQyt2iP6veYqJxSLKHQ99f102VPOo/qfOt7GLWrS7dvueWWXNb9jbfrBRdckMu6RqZU2l/nV++f2p/8/oP+1bY9a2Mpmk+1DpFURMebSyh0/ta9p/9+2GOPPXJZ51DfK+m4d8mSSi8WLVqUyy4HveaaayYsp1TuWaMwClO9Zkap0JvuYRztp76XUzvqONI5NKVybOrcqxLilMp116Wkai8dl5dffnlxndpOr/N7jmqfydqbNnleU8md2i3aH+k8qSEzUirtttdee+Wyj9ktttgil30+1d8gV1xxRS77nKnrop9T6fE4bYinDQAAAAAAAABAB+GjDQAAAAAAAABABxlKHtXv97N7oruXqquay4H0WKOYa6T2lEpXKXfTV5eo3XbbLZcXLFhQXKfujnrOXa/UFdXdi7WO6vroLsR6XSQ/0Gjw7v4UyW4G17bp9hbZUI+buoi7HEAjdLsrv7oM77777hOWUyptrWW3tbp+e9upu6m6xblrndbRXVv1nurOGEUDd3f0cXHfffdldzwfR2oDR2Unakf/G20XdRNOqXRH1LY96KCD1qjjRH/j9dVx5C7nKoPSMeuyC3VbdFdZdXdUN9QoC4AzcBFv2wV1cD8fb6NkdPAxoHOQ921181dXb3fl17Gpbe5jUceVu3erfEbdk10OoK78UTurm7lf11RW1jaD/uHzYZSNSd1p9TpvFx1jnkVG10JtW5fWqKuw3l+lGimV66dnkdl2221zWaUVvrbqs88555zinK4Bup76nKDuyn7/ccyx/X4/9yu3oY8dRecQtW+U/VLbIKVSOqp7kYMPPri4Tu8ZSb91Hfd5Xe2mc6vaNqWyn7lcRuVvup64pDGSuI1rndT9jdsxWqe1rrp++LtrX/Q2072inlOXfb9uzz33zGXfj+mY8Mwk+m4qOfQ9qvZJl4Yrur/xdbHWNimNbywObOhjX8diJH/Tekb7DZeH1mT7Pk/qvKvrp+9LdI6PMsqpnHXhwoXFdWp736PoHK2y+MiGUXbftqntbyJ5or5vlAlVx4DPgboW6lzpe1m9Tstub93fuA1Utq/jz+cOXccvvPDC4pzuTXT/VJMjpjR5oRhq940yHdX2YdHvZJcq6j5l5513zmUdeymVNj3wwANz2fuEjk3PHKs2Vdu4HFH3M5EESvcvTTOhNgVPGwAAAAAAAACADsJHGwAAAAAAAACADsJHGwAAAAAAAACADjJ0yu8BrndXPZprD2tp21xvXUsJnVKp+dSU367d1xgMqqWLtMlej1qKQ9WnplRqFDVmR0qlLlG14942qjV1HepAkxelDB+WXq+X28W1dlo31yjqOdUlum5Qdaaedla1iGo31XX7s1QP7vrmSDOv99cYGK5vVi2jx+JQ/b++l9tD29HbVPtdlM56WDTlt6cg1Hf0eAwaq0a13a7P19gKHhtA456oDljHg9dDn+WxjnSc+hjQZ+u76ByQUmk7fxfVr2qaPq+H9gXXvA5ibPm8t64M3t3H2yiphV0vrOPIYznVNN+qCfbr9t5771z2saj9XPXHKZXtrPpvH0eq9XXdr869Otb9Om3HqE3Hpf/2tK767lFcCn0nj+ukWmyP9abzr/Z7t7eup2pTX/tqMVocfa7Pa5rW3ceixj3R+cHjKkTr7kDrHsWgGoXB+PExrvOOjzE9p+PN50KNEeNrkI4/TTXr8Ta0LbWPuA3Vbv4u+ndaD49RpfOf10Pn2mXLluWy7220X6jG3+vcth0HfWcYO+pY1LnNY0jpPTx+idpO9zQ+Fvfff/9c1nf3sa3zha9HulfW8axxTVKqx7JKqeyjGncxiq/mdhz0obb3NoP50NcIXWei+Bh6zmNlqA3dNrq30VgZHgtFx4vazedubX9/F62jzn86H6RU2tTHitpD50m3oa4vvsfSvZmvUW3h63QU00br2jR+pv8OUbvq7xCPVbPffvvlsq6R3me0vt7Xtd+p/T2ttNrO90g6p+q85e2m/cTXzEE9xpXSPdpPNd2v+r6xlpo9pXKPr/Op/6485JBDcln7hM93ajd/lra/tquvITrH+75Ex2LTfZS3qfb92h4VTxsAAAAAAAAAgA7CRxsAAAAAAAAAgA4ysjwqShvnLna1VJju7qYuS556Vt3a1H3Q3d302equ625Zep3Kl1IqXdfU/dclUHrOXVtVhqFuyJpaMaXSlc3ThA7cucblyh+lxI1c4bQto1Tq/j41t1R351Npk7oY+nXqbur1UFdE7avumq4uwi6XUVdHfRd3i4vc/8blqqj4M7U+LvlSG+j7ubxM3UM9Jbu6omq7eD20PfWcu1hHchd1T9c+6e7i2u/8nM5NOseoVCelsj3cDXnQ18aV8nuYa2puqd7+kSStJqXxeUzHh85p7pqr/cXnU53z9F18/td3cVmfHuu4b9Mtvw18Tq1JbVMq56XIVmoDlwOr27CuhS6Z0XlP20zTsadUjj+fE/ScjhW3lc4PLiGpyTO1b6VUbxut/7jGYk3OndKa8jcdcyrd8LGobeJSCx1/2l7u8l9rc3fDr6XMTansB3r/W2+9tbhO6+G20bGv496lObr/8rE+LhlGSve/s+9RI/mlXutSekXHospFUyr3hyrrVvlSSvX2c1d8lT37mqlSDnXFV/f9lEq7uuRD7a/j0vuC4v16XHvTAdHvjGhdjH5n6HjzMAw6NlWe4b8ztI/oHsv3W9rPozVT9yKRBNb3r7X9nPcX7e+TbcOJaPpbQ+3v64y2xZw5c4pzui7qb8lHPvKRxXXa73VdXLp0aXGd2tvnOW1PraOvIzp3eJ/Uv9NzbsdIkjTu3xrDyHwUtaFLaLVve79Xu+2xxx65vM8++xTX6Zocydi0josWLSrO6dyt86n/5tcU4C6Brv0Wivao0W/wGnjaAAAAAAAAAAB0ED7aAAAAAAAAAAB0ED7aAAAAAAAAAAB0kKFi2vR6vazVcq2parFct1aLY+DafdV4ul5MNYX+d4pqSFXr7RpFrZNr5lXvFqVz1nq41r2Wms11h1GKr0Hshra1igPbDVOXWuwM139H8QxUS6yxSry/qG4w0udH6e+0Xqp99bSLmoLWNeXaL1SX6G2j7VizYdtoym9/d21PbzMdf9ournev3S+lMn6Mxojxd6+lfPUU5aoh9T6j40qvq8WcSWnN9lB0TvDr9P4+vw3q0fZYjHTCTa6ppcdMqdRJe9peHYsaf8F142orjVXj2v0oha/GWdA2j1K/+z20Xh6zqCnjjA02GCPD9A+1nb6fz6k6xvycj80BHg9F2/3aa6/NZU//GqF11Lb0OAtqx+j+0Zyq+LlxjEXd2zhqJ49FoH9Tm1sH96/dQ/c6Orf6++kcquPP4+TpHOcp1zUem/YJH2+67kbpeXXejWLO+dw0rnUxpfvr23QPk1J9Ho1SOPv6UYu75e+qY0Lt6PNalHb94osvzmWPe6HoHsbbQ2NzqI3djtH+ZrBnanture1Ro5geakN9H48touuOpwXWe+qa5vOsjiONAeTznV7nNtS1Ve/vvyV0/o9++0Qxm/S9avPpOFjX/Y2OU7ejzqNuR42P4r8lFR0D+lvAY73p/X0N9lgsA3zejGK7aBtEMVCicTaumDbrasNajKKUSvv6bxCdezUumP9O03vqHtV/Z+gap/vflMpxq+PBnxXFLFKimE0RxLQBAAAAAAAAAFhP4aMNAAAAAAAAAEAHGTrl98Al1N14olSu6goWud2q65G766qLm7oy+bPUpVTd3dxVSuU5Xg89p65qLh1QNypPA631iNzA1bW15u7Zttvb4H6RG2zkBq7v4K58amt3AVRX7Sgd+3XXXZfL2sY33HBDcZ26r7qLYi31m/cDdY/09lDX5Uh+o33aXeb0OJLtDEu/389jJEpt5y6H2i7a97xumlo4St2u/V7HTUopXXTRRRPWyd3F1Y4qjUuplBmou6S7LaokIJKo6Tu7rbSv1fp/E1fRUYjcIv2ZTesQueOqy7W2j8uedCwuWbKkep32M0+jWnPD9zk+mk91zh9GSjMZrF69OrdhlMLR57naHOh9W+cldwPX++t1npZU1yMdKyqVSql04XeJldpObeWyYT3nc5M+W6/ztqn1mZTun3/adOvv9/u5rtG66HIZtXe0Rujc6BIH7Qfa730Ouvzyy3NZ3z1aV7wv6TjVudUlNrp3chvW3Me97+vfRVKBNtfFlOr7m0jmpnXX+rgUQo99P6hjU23qKdOVxYsX57L3Zx3b3kZqOy0vW7asuE7Hkb9LbV30dvN5Whm0ads2HMwpkcTN1zSdQ6IU12p7v4fudbTs65HOY5qu29tBr/P9xs4775zLOh48lIOOMX1WSqVt9LpIqu6McywO6jHM/kbbSe3o16l9XI5a67M+FtWuV111VS77fKj7D98P67N0fvVxpPbx3yF6Tm0QpfWu7Qvb/r3YZE8V2VD/3sdA9HtR9yK1fUNK5V5U59NImq33Syml+fPn57LuZ3w8aL/QNTKl5jZc1zGGpw0AAAAAAAAAQAfhow0AAAAAAAAAQAcZWh41wF2wahKolEp3JnXLdxclvYdHWldXVHU19oj76hKl7kruHqhupP4sdeFStzvP0qCudf4uirpnumuXuia6y+6gHdt2Wayh9fRn1lwAvc5RRiJt11qWLz9W932XQKlN3e1OXZX1fpHbY/TOSuR2HUUUb9uOg77j7nfqBu1SJO1/c+bMyWW3VRS1X9tdr/Nxr/WoRelPKc66ssMOO0xYD7eNuqy6dEev1X6h0p+UYjnRwHbjkkc5UbYHPY6yaeg7uCRDbaPt6i6lN954Yy7r/OfSAJ0L3YY1CYXLHXVOjiQqyjBu1+PMHlWTCWif8vGhx9p/3VZRVj9tax1H7n6tz1IXe3f1jvqdXqvziI83PXa71aQJ0bro8gZvxzbo9XrVjDVaT99H6LHubVxGpePN18xaphuf47Rv6Zrm0g2VJ0bzaU0q63X0PVat37o0J8rgU5OVtUk03n2cqh1Viu8ywwULFuSy27GWvcjXu1r2KJ97o72y2lH7lmYySqkcOy6FrGV18fEV2XFw3HYGoto6W9tDplSOF51Do/fx8bHddtvlso573/vrHBr9DtC+5HJTHVe6t/WxqM92+9bkMj6mojVknPKoGtE6o3WI9qHRGuH7kwG+Vun+RtvW209t53O7ZiKKwgBEEm99lyiTW7TfmwppeO3ZOuZ0HEVZfj2jU0065euiSt503+NzktpNQzL4PSNpq47vSH5Vk9v6uYiaPfG0AQAAAAAAAADoIHy0AQAAAAAAAADoIHy0AQAAAAAAAADoIEPHtBnoCj2Fo2rvXHuoWjLVi7meXq9zjaLqwFR76Hpu1bRp/ArVqjpbbbVVcVxL0e0atihNoh6rXi6KD1KLedC2VnHQll6XKDWbakT1Ou8HqvP29LQ1/a1r/PSemibc+4umpVbtcEqlVlL7lcd6UN2pp1OM4tMo2h5R/JG2GbSbx8CI0gKqhjvSztbiFvix3t/bT/Wfqs/31KOqz3c7aj1qKfVSKucB17LqO6uu3+cYpZZGfZxxUdb1XGRr1/DqeNY2dj29orHEfGyrfXfcccfqs1TH731O+4trz9XeU6ndnoher5f7tOvYI/to/4tSoavt1AYple2i85XHZNKxE62F+ndz584tztXiSXhaaa2/j0Vtn1q6cn9WlE50HHiskgidy6LYEPquPv/p8/S6KD2tjj+PlaExbby/aJ/Tse79NtLu63jWeTKKseBjtu20tMqgHj6/R3E99J30PTw2htrV18XaXjFKA61j2/ehei4as2pHj8Gjz4rso+M5spWPvXHvUSOi9MG+L1Vqe9mUynfVtcrXI20vne80TmBKZaxAXzN1HlAb+m8ajWnj7aLza7TWaB/0thlHjDCvx6j7m1r675TKedP3N9rWen+fy3R8qO28TXRfuueeexbndJ919dVXV+urY9Pjf2kfGufcOC6iNVrP+Zit7YFSKseHjlOPhai/6fQeu+yyS3Gdxo3ysai/oXRM+d5GbejnanNo27GH8LQBAAAAAAAAAOggfLQBAAAAAAAAAOggQ8mj+v3+GrKBAeoa5O6/6h6k17n7qqdSq91D8TRh6gaoLm1+b5XdRPXwtMCKulFFqZXV3S1yt3WXvMG5Nl1P+/1+fs4wLou1FGZRqj1386+5inoaQ3X31r/xlN8qw/B2VXdTdZ/z9Jvatt631ZVSbRhJ97wfjCuFYr/fz89yW2m7u+u8jk11w3VZjP6dn9PnqUuyp8+suQjuvvvuxXU113Q/1nq4FEvPedrNmozR+4y6Vrqb+WA8t+0G3uR+0TjV93FJjL6fu56qO2iUnlDnQnXRVwlGSinttttuueyup+parvd36UzkUqrvGV1Xu9846ff7ecz5+Nd6uwt3TW7ka5razqU7KhHV+Suah7QeOr+mVI5hnzv0nvosr5O+s88dOq70ftGc6i7tg/u3vS4O2sj7lL6rS2JqsjZfy7Ut3a26Jkt2qWgtXbrKS1Mqx7bPCWobnSd9DVa7eX1rMtVoPo1cydum1i+0Dl7X2lj0fqlzm99Dj3Vui/ZIaju/LtqjqpRKJb8+f+s66Wuatof2C98r67v4nm4csuFoLKptfN6pyfH8fXRcuXywNp59LlR77Lrrrrns402f5eNU23zx4sW57PP/pZdemstuX22P6DeY2jC6R9vU+oceRzL1yN66Vnm7K5GkUcezlt0GO+20U/UeitbDQzHUfhOmVL6n1jeSHU1WevYao+zD3NbaT2tp2lMq5WTet3UM629EH7O6R3W5qc6FixYtymXfN6tkMpqbIknpukr98bQBAAAAAAAAAOggfLQBAAAAAAAAAOggQ2ePGrj9RBmiIvQ6dxdXN2S/n7rGadndbtUlSl343Z2/5g6bUpm1oWnkdnfZUjcwdaeLsrO4y9zANavtaOIDl6woC0fktqV2cxc9fVd3T9N3V7czd5nTZ0eurOpu6m1UyzbmsgElkhI1deGM3BnbtKPKo9yFT9/Dn6kuvxpdXbP/OO5KqHIXdSl1eZm6Kmr7Rdmj3P166dKluax9zeurY9bvX+tr3sdVOudtOnB7nSyX1CbZM1Iq38f7qLoPez+ozV3uoqo21DnUI/OrJMPnbh1z6l7q8ih952g+jVyEpyKzlI5Fd9PWekdu6DrPRWurjzFdn3RedqmitpOON6+vzh3uIq4yDF2Dfazosd9fx63LnhR9z3Fni0qplA1HWSyiLJG6PnlGP8X3IrqHiTJX6f11nXUZldrX21jl3pFsQM95ndQe2r+9bXxvpkSZC9cFlfC7HXUcRfO4XhfJTCI5WK2NUiolN/KMnAAAHyVJREFUjZHkVG3i9dUMKip78vE2ijTB+0zkzt90nRqWQZ+orcN6zUTn9N3chlGb6LxZkx75ddtss00uuw21fTwDlfYR7VeeWSiaa7X++v6RBLP2OyOl9vc3td+LUSY3PVfLAptSPD5qUkgfH7rGafYoz4Cpf+e/QzRjVK3uKZX7IJ9Ta5nEfD88FZmlBvaJQhdE80JtXKZU7lncvnqtyri9b+s5lSrqPJtSuU763lOlwjq3+u9FHStRNtDo+8K6gqcNAAAAAAAAAEAH4aMNAAAAAAAAAEAH4aMNAAAAAAAAAEAHGTqmzUCr5Xpe1WtGqUJV6+U6R/07jX2QUqlb0/t5XBzVzKtu0DV3qg2MUs+qHs+1aapb15R9KdXT6EaaVL//4LjtOA2Ddnc9r2oFXXtY07q6rVUP7XpMPRfFgVE9qaa9dC2p9xGlFvfCY0JE2kNtn1qq+5SmJu1wr9fLfcnjJ2hsFk0NmlLdjpH+VuNmpFTaRHF7a9vquPR4G5p63FOy6/hT7b6nL1V9s7+Lto++l9tG6+W6/nGNxQHeh5qmU4x0xdpnfY678cYbJ7zONd+a6lLnYLehzgM+VjTtbDTH1NJ6pxS/5yjXjQufU7Wf+vyl76tzTxSXwtH+rG3rMUpUz63jbcGCBdV7+xjTuUOf5fOmrrtu41qf9HfWZ/mcNbhH2/Yd9B2PN6AxBjxFem0+9TlZ39vTa+t6p/030sLreHNbR/OktrOun6rpT6mML+D31z2Xxjlye+izohT0bTNoQ+9Take3T238+f5S45dEMQ2iZ2k7aUyNKA6Jt5f2UbWd21v7axSbqJYuO6U4jsy47DhoW/+NoHsMb1c9p/Odv7fa1NdFTdMcxevTe2g9/H46Tr2/aB+p/UZKqWxzX3d1ftX7RzEevR7jjJNSs6OON18za/Xxfql9L3rfKJ6Ptqf+jbez1t9jDuk8qvsqH89qK59Ta78XnamM5xf1G/9dG6W8VvQ7gu/9dSzp2PbxrHOcrltRWnWPLavfL6IYSHrO37lpfK913aPiaQMAAAAAAAAA0EH4aAMAAAAAAAAA0EFGTvntrl/qLuguP+rOpK5w7oKmrp3qlp9S6XamrmXuKqX1qrkf+t9FaaDVLdLdoRRPL6b1VdcudU1PqXSV8ncZtGPbbm+D+7mcJZKT1VJYuoueXueuuioP0HZwqZ22ubqtefvr33l/VBd0dbtzV70otWlNruH9JXI9HZdco9/v5/upS29KZTv7+zatQyQb02NtI+8LNXddd03U9owkVpELsR67K7PWS+/hMgV1hfT0g96X26aNVKo+Pmp2Sql8H73O0wfXrnM7qWzAU5vqsd7D3Yy1/aPUx5GMSokkZ20zaHt3j1cXe3++zl9a18iV3N+pJlly9O90rVLpmj87Gs86p/o9olS5unZrW0XrYk0u5n2wLVwaGblc1+b+KB2xz0+1lN/e/nqs7er30zHrbaT3iNJXR/OpvpvOp95uOh/5ePZx0iaD/uHrdC2dc0r1dK0+FrVtff7Sa7U9/d31WMeOy310nfT6ap9ReZTKrby+LsmopYiO7BjJIMaB9z2VmERjTMs+Z2p7+bvWpIWzZ88urrvuuutyWcfUvHnziuuuv/76XPaxqPXQcy7JU/mHpiNOqbSHvouPL73Ox3q0brRFNN6c2t4n+hvvJ7onrv12SalsFz131VVXFdfpmPW21WerDTx8Q5QuurbfjtbgmoxuXPucphI0Pxf9xtV139/nyiuvzGWd1/y7gbarjkuvk/Zz/82ka0U07ypNJW7RHBlJIat/s9YrAAAAAAAAAABg0uGjDQAAAAAAAABAB+GjDQAAAAAAAABABxk55bfrhVU/FsUeidIoq1bN9cIapyOKL6KxZFRj5qmpVZPvmnnVu9XSjnk9XCNXS/Ptejy9p7fHoK0iXd0oDNrF9XNaT9cD6jl9N0+Bqppj14+qTlTTRnu6UdX0aj9wvbDqAV2brOh7ul5Y4xVE7azv4ppg7YOuQdW/i2InDUu/3w/TkNfqU9Paux0Vj++i9mqqM1Y7apyPlGINbpTWXdFx5PdT++t77rDDDsV1N91004R/k9L9sV48Ds5k0DS+jc+7euw6bLWh6or9Om1XjTPmc6HqgL2+Oub07zz+gqaWj+JoNNF1pzR62vBRGDw3isHg7aLrTnSdarF9XdTxp23r417P6Tznumxdn7wvaB11DHtfUDv6nKfvEqXK1et8LA7msCbz3zDUYgJE40/nUB1vPp/W+m9KZcwntafXQ8/V0sWnVI4Jbzudv6J9VBQvSK/VtcH7nM4rXg/td77+ryuD9vX6RDaI9i2K3tP3HHp/XWf9Om0/7fe+HqldPRbEokWLJnyux17TmDlRrDetb5RKuxZHZlyxbYa5r86n2rfVtimV7+rx9XS/of3AfyPoGNN7qF1SKudTv4fOcfpc3YekFMc40bGjdRrmd4bWq809aoTaJ4pPqDaI1kXfJ+qeQ+MA+TjSsant4HWaNWvWBG+xZj30Hj6PqO3cBtrutXk+pfg3yqDOUcrwNmkay1PxdtXr3Ia6tug8ttVWWxXX6RjQdTeKB+Rzgt5f9y8e76kWYzOleppz35drvUbZo+JpAwAAAAAAAADQQfhoAwAAAAAAAADQQUZO+e0yEyVKr61uSe4uqG5D7tpUk6C4+5i6lqlrk99PU9tG51RG5a5pWid3d1OX58jVO2LgKjVK+t+IgdtVlFa3VpeUShu665e+t7s9q1uqumu63Ehd1dSNWt3WUipdFiMXNHXT9r6pNnVXWa1jJD1QmroJriu9Xi+74LkrfuRiX3Ph8+vURdpd5bXNdB5wG6grvro6uqtp03Sj2l/dhVuvcxdMtb/KGP29ohTyg2vH5QYe9ZPIhVLf2+dTtVOUxljL3nbaDpq+1PvcbrvtNmGdUirbXNtP75dSOXdEaTW1PcaZxnsYBvXwdTGSAyvat/0ees7XIHUpjly41a4qsdpuu+2K67RvuSxSbac29jGh64PbR9cELUdzak3m0rbtB23k4ygam/ruUZphnVv8fXTd0TZ393qdT7UfuMxQx7qvd2q3mtwtpVJS4O+i86baMErrG8np22Zwb3eBj1Ky1+QJvkfS/YiPD50r9Vk+l+lYVMmprznaRv4slVLp+uZ7GO2T/s5qu0jeGo31ca2Hg3f3vaG2iY8jPVa7uQ31Hj7GamPdZdF6Tw294Ous7lOi3zsa/sHTervkTdGxqH3Y7VJLKZ3Smuv1OPBnRGOxJi3x8ay/0/z+ui5G16kN1MY+p2odvd9pvdSOLnPTe/heoCZfi+bJyd77+N5QiUJt1NKqp1SOCe+XOm/qs71ddSxqeJTZs2cX12k/qIUiSamUFrqttU7R94B1lUBF4GkDAAAAAAAAANBB+GgDAAAAAAAAANBBhpZHDYiiWLurVM39PnKpcnfQmruVX6fuiOpu6q7j6t7vLkrq2lRz7U+pdFv0yNc1CZe7ZUWuieNyfxu4Z0XSGbevuoxFLovqkqaugn5tJK/Tc/pc/xu1oddX3Q21vip3S6l0C45c4dRufl3kNjhOedSgPaNMMe6uqzIWdYn37GpqK38/dR3V8ed9e/vtt89l7Wvuwq318PZSu2pf8PGmrq3qIplS2T5RNjh1s6xlJXJX98kgyuSmbp3ueqo2VFv4tRqN322jcgAdf7vuumu1Tj6n6d9pBjlH3fyj7FFRhihlXGNvIgb9xechrYOf0/5Wkx7pvVNaM3NCbV6KJL9a9uxRun5Ga/zSpUtz2dtZ51iXfOj4UXlGJLNwicRE91pXer1edS2Osn6ovEznJ8/e4uukojaNpIo6jqJ5V+3rc5zuWbRdfT7V6zxjWU0W7vXQ+kcyl7bn1MFzo32d91ndS0S20rp6vXUd03PR3Kvjz+uk0qkoq4/ax9d7tb+vizXJRySp8zWmljVvXanZMJrva3I/f59IuuC/Jwa4HFvbWedx/52h84DPpzomdP/i85DOob5/VdSe/s46Fl2mNS6JmxLZLZJHaRv5HKJjbM6cOcW5WuYvHx/6G0XnV5d/67NdSqpyHbWxz736W1L3Ov53TaU1Pl9M9u/FCO3DtfU7pbhf6njWMeZjVP9Ox5vbUNfF6NuDhuGIpMwq5/d71sopxTZUyB4FAAAAAAAAALAewUcbAAAAAAAAAIAOwkcbAAAAAAAAAIAOMlRMm16vl/Vprs+MtGmq7VOdlscoqaXsS6nUEW677bbVZ9XSAm+zzTbFdaqXc62v6g1V6+2p91RT6RpF/bsoZWsUh2AcMRl6vV6+b6S1c12t2jCKv6DvGmkKtf1do6j30L/RNJcplTpqTy+u9lCdo1+3ZMmSXPaU4qpBbao9HEaD3RZRCkcfR7X+rGnWUyrHpmt4dVxpn/XrVC+s84Pr36MUwVovLbu2W8ei2/HPf/5zLmsMgSj9u+uRa/VbV2p64abaZR2LHm9AtcQep0HnUB2n3l/UbgcccEAu+7yr1/kY05gL2sZuQ73OY+uorZqmTIzatE16vV5uN+/b2i/dBqqvj+JiRSlLNe6F9lnX+Os5jaESxaLw9UFtorbydLhqV09fq3Oqtof3GT3nfcH7aFsM+keUutrHmNZN1xzXu2ustygOX7R+6pjVOvpY9Hg6io4JnU/dhvouPp9qPCN9ts+nUZrccaGxiaL9lI+3WspdR/tlNN9q3LcoFp/Wyfc3+iyPC6FxNK6//vpc9r2sjkXfo+rfRSnpm8YQa4ter5ft43Xxvq7otTqfPPzhDy+u0/Hh/UCP9e98P7DLLrvkss7JOh/73/m8ojbUuDVXXnllcZ3u03yc6vyq9Yj2DJO5Rx20ZxQ3x21Qi3fl7afjw99Xx5La22MO6Xw7d+7cXPbferpmevwvXQt1r6njy//O76HriNoxipE3Gb8X9b7DxA+sxXH1tVvf1dctXSd1P+NzgMYM07VU10t/ltv3uuuuy2VdF6P51Pcleqx9uu09Kp42AAAAAAAAAAAdhI82AAAAAAAAAAAdZGh5VJO0mJGrVJTmU/9OXcJTKl2n1JXT3a00Bae6V3lKY3Vdc5dDdYm6/PLLc9nT1V599dUT3i+lNd3fBrg7lLpPutuXu4y3xcCt1+uirnhuZz1Wu7mbmbqF+zl1C1a5WmRDraNfp+7J7sKtrqfnnHNOLqscyq/zfqCumZFrtbZb5HbdJjNnzsyugO7OrW7qkdylVk6pdDP0+6tN1G3U5VHqiqp92/tWJLVQCYm6EPvYuPbaa6vn9DhyE67ZO6VS1jEOInfmyGVS511Pr6xj0W2oNlC3YJ8ndQ5V+3qqaLWTyidSKl1P//jHP+ayz6faxu56Gq0vStRu40yJOZiLfA7XPuX9Xt27tf0i2ZhLLdQ+es7Hc01SpDKOlEobuPu1zpXat3zt03v4vKxrQjS3a3t4m0Zpb0dFJW6+L9Gx43WpSRL8HjpevF3VViop9fTuaqtIsqVzqKfr1rZTO/l+ZfHixdVzPs8M8D6n65Cf89S7bRFJ+NWOXh+1l45Zt6PaziX3ut5pX/C5UqVyWvYxcMUVV+SyjzG1o9pY18GUyjnW1zC1QTQ3RvvCQVu1PbcOnhPttXwsapvru0X7I5eR6pysz959992L6/Q3yI477pjL3g5qmygMg9paf1ekVK6nkSxcidotSineNgOb+DN1XPk6XZMA+V46kobrb42azMafpde5NFXnQJe+1ubba665prhOpWx+j5r8e5jfGj7ftc2o+ymtl/dXvafOhSmVvwPVHr5nUXmUSqJ83tU1zedTPXfZZZdNWE6plE7574ymEuBojxrJCAfgaQMAAAAAAAAA0EH4aAMAAAAAAAAA0EH4aAMAAAAAAAAA0EGGimnT7/ezbsv1W6pb8/SEqkVUbaDHF1FNoWtzFyxYkMuq63RdscZCUH2qx1moaYJTKuPYqNbNNakaq8E12jU9d6TfdM3moP7jiovi+jnV2kV6SdXiusZWj1Xrm1KpO9VnR3Fgalpzf9YFF1xQnNP4C6oR9jga2gc9jkZNPxppO10/rTp1T4m6LvT7/fwsH4taB9d16jltI0+FqGPC40tpW2hf8HvUYk+4/lj1vR4DQ+uhdlQNeEqlftjHs2pPdW7yeUrbxvW6g1gTHqepLYaJCVBLp+j9N9Jha1/Uv/O4RBonRceDzn0plW3+hz/8oTinumAdf54OWuvofXqUmAlROsVxpW73MR6lu6ylv/YYItrnXEet2uz58+fnsscp0FhF2u/9frX5IaVyjOn40zUypTgGg87tGufA7aH29zYd17o4GFe+LkbxF7Ruajefg3S8eGpnvb/aLYrlo/Xw6zTGgo8xtc0ll1ySy5qq1q+L4mjoXO71UBv6eNZ1qe2YGoN5apj9jfYlHRMeX0RjJriNdf+qcReieD76XLdVbaykVI4/nV+jmH2e8rsWg8HtqH3cx9xgTmtzb9Pr9XL/HmYs1mzobaJ9T2P3pZTSvvvum8vaX7ztNMaGrp8+n+p65/Ok/sY599xzJ/z3lMo4Gl6PWpwm7y/6Lm5DXQ/anlNr62wUW1DfSd/D10WdUz3OiY7bffbZJ5e9P+m7R31Y291j1fzpT3/K5dpeJ6Vyvfc5r9avm8YzTKlZevV1IUoV73NcLRaRx9WKbKhxbPU3iPdtfbY+y+2keyWf1zXW4sUXXzzh36RU9kH/rRfNTTWiuL61sYOnDQAAAAAAAABAB+GjDQAAAAAAAABABxlKHpXS/e477g6l7t1R6jF1DXV3UHUHcvcxPRelSdR6qTuiu5KpC7G6CadUumypi5W7u6k7XZQWWa9zSYbibqmDd2nT9TSl+9vCXbj0+ZFrsdrG3cfU9t4P1PYqNdOUwymV/UJd4VziFrlwq4upuixGab3dhkqUMrGp/K1NInmUSiHcxU7dd/U93CVX28XTJOqYU5dGHx8190aXQOkY8/6kfUH/zlPxad9yGZ268Eeu+JFcY/DO47LnqPfVcRq5v7t8UN1UteypTdW1XF1DfRxFMtJFixblsrp6u5xL36WptGlc9hiW2pqn872PU627t6ei/dfXAj1WeYajbsM6V6o9UirHmK/PtbS0kZwrmlO1Tr726Rzj9xjXuliTR+nexvul1kHHn8sH9R1cSq321fSlLlVQ+2pqcLehjtkofbDOte5KHqVM1vUusq/vERVfQ8eB20rbOXonlWm6lPf888/PZe/3ai+9v685Ks/RMeXSWz3+zW9+U5xT2ZPOvb5HUjv6eNF+rnNTtIeJ9j5t0e/3c928LjovRL8z1PZuJw1/4L8f9FhDL/hY1GerfX3u0HngvPPOK86pDXXv5OunrpO+hjS1YSRlmQx8LEZ1qP12cmmN4n1hjz32yGW1qUsad95551zWMevjSOdHl9upnEZt5/XV+0fpoaPQEcpk/dZo8rxIOqW2cfmgt7Oittcx5vtc3Tvp3t/Hve5nFi5cWJzTPara0OdkfZdIhtZ0jzqKzfC0AQAAAAAAAADoIHy0AQAAAAAAAADoIL1hsmjMnDmzP3AVjv4uilyu7kDueqpuyJ4VSiUfKqfxjDWa/UTdo7y+6irlrszqIq5uWe6Cp65e7u6m7xZlAdC/c3erwT1WrlyZ7rvvvlZ833q9Xn9w38hOjl6rdY5s6JloVEqj7t2eZUrdCFVi4+766hbnroh6Ttvf3VybutjrOw9jQ+3v995773n9fv/ARg9cCxtttFF/0Pe9X0b9TdszknypfTRjRkop7bTTTrms9lbZYkqlO7/2LXc5VJdGd5esZfdyu6n93aVUbaLv7K7R2m7u0j6QuaxYsaLVsSjlNm5ZoDb1d1XZjmbC2G677Yrr1L6R66lKClz+oX+n7e/zTdOsB5Hr6RDrWWtjccaMGXld9HEUuTrrtdG6qHIKz7Cg0kW1o47flMqxqDZ1OWLkIq7zb7T2qQt6U/t4u+n4rv3NqlWr0urVq1sZODNnzuwP2jnKWOM2rEmK3YY1qWhKo9kwmk+jzDkqydBx6fOpj2FFnx29s/YllyNpu61cubLVsTiY66K12Pul2jXKwqPHvt6ptE33Pn6djj+th8t61VYuX9b1LtrfaF+I1pho7o32N4O2XrlyZWtjccaMGX2XS1auK45r7xdJL/V3RUrl/KrSGb9Os05FYRJ0/PnvDF1DIzmi2tT3etoGaidvm5pcJaU15LetjcVer9dvIsVqKruJ5l7PkqpzrI5F38uqXdUGvr/RvadnVaxlFIoyLEc03d/UJOSrV69O/X6/tT1qk71p0/2rX6fzqdtQ18zab8eU6pncfD7VfYnL0XW/rzb0+U5tOqqEv4kN//9zE45FPG0AAAAAAAAAADoIH20AAAAAAAAAADoIH20AAAAAAAAAADrIUCm/e71e1hG6Pk+1X1FqQY2l4ClfFdfwapovT++s1PTvHqNC6xTFOdH3dM221t/Trdbiinjb6Dlv0ya63mHp9Xr5PaI0bY7WuxavZ3D/AZ7aWW2oaSo1ZZ7XQ+/nOnvTxRfnavZ1jXqUdrZWj8iGtVTRKTXXtDah3+83up9fo/pb1YK6xlP1wz5OVdOrulPXfevfNdVUe/paReOmeIwW7Vs+FtVeake9n/+d9+vNNtsspdR+usyaFrhpbJYo7aKOAR8fqtuN9No1mqasHOZcUx1w9M4Ro/7d2pgxY0aOUxHp2P2ZagPVc/t407/zODM6nnVMaNyMiepbe5bOZb7Oavvpeurros7TGvshpdL+tft5Hb1NB/eM0k2vC1Hfi+yrextPS6r38LGo8Um0H7gNa+/rddK281hvWo9oXVR7+FxbG8Pel7RfeB09fkFb6P5mmHgE2rbR/kbr7TFKNH6MXufjQ+2v7e721b/zsajvFs1lWn+3Yy22QhQLqGncsXVl0C5RiuuoLtp23i/177zN1Yaa+jeKkxftbWrjzZ8drac6n7oNa33a3yvao44zBfjg3tHeJOq/Wrdov+vvq/OX/g65+uqrq/XQfu7303PRbx79O2/XKC5mrQ2isThZdhw8M7JTNBabzh+eDlzbWeO2RfGaorXa4otW71HrE34uqkftbya6Z+1c7X542gAAAAAAAAAAdBA+2gAAAAAAAAAAdJChUn7PmDEjp4t21yOVWrjsQCUU6qro7r9RKiyVrqgbsrsaqVukukC5O1SU/lFd3KKUczUZVVQPf5a+S81Fsu2U3wPXPHfbUpded+HW9tf3dklR5N5VS2vr9ai1SeRi6e1ac6WMJGF+TutYc59e2z3UDbLN1KaaotbdNTXFobscqgRIXQ49DW3kaqv20b9ziYP2J+0z3re0PfXeXv/IhVjrGLWHygVcRhWlzBwcL1++PN17772tp/ye4Fwuj5pacIh6NDoXrRVtpOGOrmtajyHabSxphn3e0XXRx6L2dR0T7gKv48P7pZ7Tv/OxUksv7mM7kh/os7S+0ZzqUtLanDBM3x1ce9ddd7W2LkZ7G50nfI7TPYyei+Rpfn9dQ/VZ3na19OKRK/8oqdS9jl5f7bf6zsPIubUf33nnna2mGa5Ja7RtfQ1Se9XkS34c7Rf0fpGsI5LOR3KH2vrs9dU28HrUpFl+D61HbZyuWrWqtZTfmip6mD2q9stI9h6FJNBzUX/WNokkGbXr/NpIdhFJbGvyoajfRnKNVatWtToWa9Ka2u8jr2u0J2u6b2kqDYvWvqbrU1P5d9N6jLKnazvld+1crc7Ruabp3f1cNBe2Id8cZY867n05Kb8BAAAAAAAAANYj+GgDAAAAAAAAANBB+GgDAAAAAAAAANBBhkr53e/3s1bLY094HAlFdYkeR0KJ0nDXYsu4hrSmk/c4JJEeT4/1/q5Tj+6vGuGaFt2vq6XdbDvN4qAtXbNbi+Xjx1rPKO1ZlMIy0gFrutRITx31gyZ193tGaUCb6iajlOJt0u/3c/08rW4UU0LjS2m8De8LqjP2lJl6Tsezx7LydLMDvM/oszXOjl+r77LllltOeO+U1rTBsmXLclnfP0rn5/PboE+OK+XpqHFgmjLq/Wp65KZ63qgekb45+ruINmLrDEu/38/zj/avlMo+G+m+NR6Nj0X9Ox9jtdTJPvfqPKTPjdZFv4e+i5b9nbW+Hp9H09fqGPO4BloPH4uDNmhzLPb7/Xw/f14U60D7lP5dtC76nFxrL187dB6OYvJZHLVUQ5/r/SgaR1EK4tr9vU9H9WoLr1sUW0b3D1rXUe0YpSqupW6vxVHze0d197UviidRi9M3zLgatx2930T7vGjeqV0Xpf6N9ny1+DFRHLBo7lCaxmpJqWyP6FlRHxnXHjWl+98x6pcROgaisRjFEoqe2zT2yCj7G3/niCh2T9P7R/NbGwyznxolpkvTlOKj7uOa2rD2N2s7N8o7R79BauBpAwAAAAAAAADQQfhoAwAAAAAAAADQQYZK+d3r9W5JKS0eX3Wgwpx+v791GzfChlMKdlz/wYbTA+y4/oMNpwfYcf0HG04PsOP6DzacHkxox6E+2gAAAAAAAAAAwOSAPAoAAAAAAAAAoIPw0QYAAAAAAAAAoIPw0QYAAAAAAAAAoIPw0QYAAAAAAAAAoIPw0QYAAAAAAAAAoIPw0QYAAAAAAAAAoIPw0QYAAAAAAAAAoIPw0QYAAAAAAAAAoIPw0QYAAAAAAAAAoIP8f6grK4f7MOHAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HYptskgyL_Vq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f948295c-8d26-4f51-a085-2952fb1a4e5f"
   },
   "source": [
    "encoder = Model(input_img, decoded)\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "\n",
    "print(\"encoded img mean:\", encoded_imgs.mean())"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "encoded img mean: 0.15291682\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HxH9OCfzL_Vr"
   },
   "source": [
    ""
   ],
   "execution_count": 9,
   "outputs": []
  }
 ]
}
